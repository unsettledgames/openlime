<html>
<head>
</head>
<body style="background: transparent;">
    <script src="scripts/docstrap.lib.js"></script>
    <script src="scripts/lunr.min.js"></script>
    <script src="scripts/fulltext-search.js"></script>

    <script type="text/x-docstrap-searchdb">
    {"Annotation.js.html":{"id":"Annotation.js.html","title":"Source: Annotation.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Annotation.js /** coordinates for annotations are relative to the top left corner!!!! */ class Annotation { constructor(options) { Object.assign( this, { id: Annotation.UUID(), code: null, label: null, description: null, class: null, target: null, svg: null, data: {}, style: null, bbox: null, visible: true, ready: false, //already: convertted to svg needsUpdate: true, editing: false, }, options); //TODO label as null is problematic, sort this issue. if(!this.label) this.label = ''; this.elements = []; //assign options is not recursive!!! } static UUID() { return 'axxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) { var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r &amp; 0x3 | 0x8); return v.toString(16); }); } getBBoxFromElements() { let box = { x: 0, y: 0, width: 0, height: 0 } if(!this.elements.length) return box; let { x, y, width, height } = this.elements[0].getBBox(); for(let shape of this.elements) { const { sx, sy, swidth, sheight } = shape.getBBox(); x = Math.min(x, sx); y = Math.min(x, sy); width = Math.max(width + x, sx + swidth) - x; height = Math.max(height + y, sy + sheight) - y; } return { x, y, width, height }; } static fromJsonLd(entry) { if(entry.type != 'Annotation') throw \"Not a jsonld annotation.\"; let options = {id: entry.id}; let rename = { 'identifying': 'code', 'identifying': 'label', 'describing': 'description', 'classifying':'class' }; for(let item of entry.body) { let field = rename[item.purpose]; if(field) options[field] = item.value; } let selector = entry.target &amp;&amp; entry.target.selector; if(selector) { switch(selector.type) { case 'SvgSelector': options.svg = selector.value; options.elements = []; break; default: throw \"Unsupported selector: \" + selector.type; } } return new Annotation(options); } toJsonLd() { let body = []; if(this.code !== null) body.push( { type: 'TextualBody', value: this.code, purpose: 'indentifying' }); if(this.class !== null) body.push( { type: 'TextualBody', value: this.class, purpose: 'classifying' }); if(this.description !== null) body.push( { type: 'TextualBody', value: this.description, purpose: 'describing' }); let obj = { \"@context\": \"http://www.w3.org/ns/anno.jsonld\", id: this.id, type: \"Annotation\", body: body, target: { selector: {} } } if(this.target) target.selector.source = this.target; if(this.element) { var s = new XMLSerializer(); obj.target.selector.type = 'SvgSelector'; obj.target.selector.value = s.serializeToString(this.element); } } } export { Annotation } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Camera.js.html":{"id":"Camera.js.html","title":"Source: Camera.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Camera.js import { Transform } from './Transform.js' import { BoundingBox } from './BoundingBox.js' /** * NOTICE TODO: the camera has the transform relative to the whole canvas NOT the viewport. * @param {object} options * * *bounded*: limit translation of the camera to the boundary of the scene. * * *maxZoom*: maximum zoom, 1:maxZoom is screen pixel to image pixel ratio. * * *minZoom*: minimum zoom, * * *minScreenFraction: the minimum portion of the screen to zoom in * * *maxFixedZoom: maximum pixel size * Signals: * Emits 'update' event when target is changed. */ class Camera { constructor(options) { Object.assign(this, { viewport: null, bounded: true, minScreenFraction: 1, maxFixedZoom: 2, maxZoom: 2, minZoom: 1, boundingBox: new BoundingBox, signals: {'update':[]} }); Object.assign(this, options); this.target = new Transform(this.target); this.source = this.target.copy(); this.easing = 'linear'; } copy() { let camera = new Camera(); Object.assign(camera, this); return camera; } addEvent(event, callback) { this.signals[event].push(callback); } emit(event) { for(let r of this.signals[event]) r(this); } /** * Set the viewport and updates the camera for an as close as possible. */ setViewport(view) { if(this.viewport) { let rz = Math.sqrt((view.w/this.viewport.w)*(view.h/this.viewport.h)); this.viewport = view; const {x, y, z, a } = this.target; this.setPosition(0, x, y, z*rz, a); } else { this.viewport = view; } } glViewport() { let d = window.devicePixelRatio; let viewport = {}; for (let i in this.viewport) viewport[i] = this.viewport[i]*d; return viewport; } /** * Map coordinate relative to the canvas into scene coords. using the specified transform. * @returns [X, Y] in scene coordinates. */ mapToScene(x, y, transform) { //compute coords relative to the center of the viewport. x -= this.viewport.w/2; y -= this.viewport.h/2; x -= transform.x; y -= transform.y; x /= transform.z; y /= transform.z; let r = Transform.rotate(x, y, -transform.a); return {x:r.x, y:r.y}; } sceneToCanvas(x, y, transform) { let r = Transform.rotate(x, y, transform.a); x = r.x * transform.z; y = t.y * transform.z; x += transform.x; y += transform.y; x += this.viewport/2; y += this.viewport/2; return { x: x, y: y }; } setPosition(dt, x, y, z, a, easing) { // Discard events due to cursor outside window //if (Math.abs(x) &gt; 64000 || Math.abs(y) &gt; 64000) return; this.easing = easing || this.easing; if (this.bounded) { const sw = this.viewport.dx; const sh = this.viewport.dy; // let xform = new Transform({x:x, y:y, z:z, a:a,t:0}); let tbox = xform.transformBox(this.boundingBox); const bw = tbox.width(); const bh = tbox.height(); // Screen space offset between image boundary and screen boundary // Do not let transform offet go beyond this limit. // if (scaled-image-size &lt; screen) it remains fully contained // else the scaled-image boundary closest to the screen cannot enter the screen. const dx = Math.abs(bw-sw)/2; x = Math.min(Math.max(-dx, x), dx); const dy = Math.abs(bh-sh)/2; y = Math.min(Math.max(-dy, y), dy); } let now = performance.now(); this.source = this.getCurrentTransform(now); //the angle needs to be interpolated in the shortest direction. //target it is kept between 0 and +360, source is kept relative. a = Transform.normalizeAngle(a); this.source.a = Transform.normalizeAngle(this.source.a); if(a - this.source.a &gt; 180) this.source.a += 360; if(this.source.a - a &gt; 180) this.source.a -= 360; Object.assign(this.target, { x: x, y:y, z:z, a:a, t:now + dt }); this.emit('update'); } /* * Pan the camera * @param {number} dx move the camera by dx pixels (positive means the image moves right). */ pan(dt, dx, dy) { let now = performance.now(); let m = this.getCurrentTransform(now); m.dx += dx; m.dy += dy; } /* zoom in or out at a specific point in canvas coords! * TODO: this is not quite right! */ zoom(dt, z, x, y) { if(!x) x = 0; if(!y) y = 0; let now = performance.now(); let m = this.getCurrentTransform(now); if (this.bounded) { z = Math.min(Math.max(z, this.minZoom), this.maxZoom); } //x, an y should be the center of the zoom. m.x += (m.x+x)*(m.z - z)/m.z; m.y += (m.y+y)*(m.z - z)/m.z; this.setPosition(dt, m.x, m.y, z, m.a); } rotate(dt, a) { let now = performance.now(); let m = this.getCurrentTransform(now); this.setPosition(dt, m.x, m.y, m.z, this.target.a + a); } deltaZoom(dt, dz, x, y) { if(!x) x = 0; if(!y) y = 0; let now = performance.now(); let m = this.getCurrentTransform(now); //rapid firing wheel event need to compound. //but the x, y in input are relative to the current transform. dz *= this.target.z/m.z; if (this.bounded) { if (m.z*dz &lt; this.minZoom) dz = this.minZoom / m.z; if (m.z*dz &gt; this.maxZoom) dz = this.maxZoom / m.z; } //transform is x*z + dx = X , there x is positrion in scene, X on screen //we want x*z*dz + dx1 = X (stay put, we need to find dx1. let r = Transform.rotate(x, y, m.a); m.x += r.x*m.z*(1 - dz); m.y += r.y*m.z*(1 - dz); this.setPosition(dt, m.x, m.y, m.z*dz, m.a); } getCurrentTransform(time) { let pos = new Transform(); if(time &lt; this.source.t) Object.assign(pos, this.source); if(time &gt;= this.target.t) Object.assign(pos, this.target); else pos.interpolate(this.source, this.target, time, this.easing); pos.t = time; return pos; } getGlCurrentTransform(time) { const pos = this.getCurrentTransform(time); pos.x *= window.devicePixelRatio; pos.y *= window.devicePixelRatio; pos.z *= window.devicePixelRatio; return pos; } /** * @param {Array} box fit the specified rectangle [minx, miny, maxx, maxy] in the canvas. * @param {number} dt animation duration in millisecond * @param {string} size how to fit the image: &lt;contain | cover&gt; default is contain (and cover is not implemented */ //TODO should fit keeping the same angle! fit(box, dt, size) { if (box.isEmpty()) return; if(!dt) dt = 0; //find if we align the topbottom borders or the leftright border. let w = this.viewport.dx; let h = this.viewport.dy; let bw = box.width(); let bh = box.height(); let c = box.center(); let z = Math.min(w/bw, h/bh); this.setPosition(dt, -c[0], -c[1], z, 0); } fitCameraBox(dt) { this.fit(this.boundingBox, dt); } updateBounds(box, minScale) { this.boundingBox = box; const w = this.viewport.dx; const h = this.viewport.dy; let bw = this.boundingBox.width(); let bh = this.boundingBox.height(); this.minZoom = Math.min(w/bw, h/bh) * this.minScreenFraction; this.maxZoom = minScale &gt; 0 ? this.maxFixedZoom / minScale : this.maxFixedZoom; this.maxZoom = Math.max(this.minZoom, this.maxZoom); } } export { Camera } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Canvas.js.html":{"id":"Canvas.js.html","title":"Source: Canvas.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Canvas.js import { Camera } from './Camera.js' import { Layer } from './Layer.js' import { Cache } from './Cache.js' /** * @param {Element|String} canvas dom element or query selector for a &lt;canvas&gt; element. * @param {Element} overlay DIV containing annotations, TODO: at the moment it is just passed to the layers (might need refactoring) * @param {Camera} camera (see {@link Camera}) * @param {Object} options * * *layers*: Object specifies layers (see. {@link Layer}) * * *preserveDrawingBuffer* needed for screenshots (otherwise is just a performance penalty) * * **Signals:** * Emits *\"update\"* event when a layer updates or is added or removed. * */ class Canvas { constructor(canvas, overlay, camera, options) { Object.assign(this, { canvasElement: null, preserveDrawingBuffer: false, gl: null, overlayElement: overlay, camera: camera, layers: {}, signals: {'update':[], 'updateSize':[], 'ready': []} }); Object.assign(this, options); this.init(canvas); for(let id in this.layers) this.addLayer(id, new Layer(id, this.layers[id])); this.camera.addEvent('update', () =&gt; this.emit('update')); } addEvent(event, callback) { this.signals[event].push(callback); } emit(event) { for(let r of this.signals[event]) r(this); } //TODO move gl context to canvas! init(canvas) { if(!canvas) throw \"Missing element parameter\" if(typeof(canvas) == 'string') { canvas = document.querySelector(canvas); if(!canvas) throw \"Could not find dom element.\"; } if(!canvas.tagName) throw \"Element is not a DOM element\" if(canvas.tagName != \"CANVAS\") throw \"Element is not a canvas element\"; this.canvasElement = canvas; /* test context loss */ /* canvas = WebGLDebugUtils.makeLostContextSimulatingCanvas(canvas); canvas.loseContextInNCalls(1000); */ let glopt = { antialias: false, depth: false, preserveDrawingBuffer: this.preserveDrawingBuffer }; this.gl = this.gl || canvas.getContext(\"webgl2\", glopt) || canvas.getContext(\"webgl\", glopt) || canvas.getContext(\"experimental-webgl\", glopt) ; if (!this.gl) throw \"Could not create a WebGL context\"; canvas.addEventListener(\"webglcontextlost\", (event) =&gt; { console.log(\"Context lost.\"); event.preventDefault(); }, false); canvas.addEventListener(\"webglcontextrestored\", () =&gt; { this.restoreWebGL(); }, false); document.addEventListener(\"visibilitychange\", (event) =&gt; { if(this.gl.isContextLost()) { this.restoreWebGL(); }}); /* DEBUG OpenGL calls */ /*function logGLCall(functionName, args) { console.log(\"gl.\" + functionName + \"(\" + WebGLDebugUtils.glFunctionArgsToString(functionName, args) + \")\"); } this.gl = WebGLDebugUtils.makeDebugContext(this.gl, undefined, logGLCall); */ } restoreWebGL() { let glopt = { antialias: false, depth: false, preserveDrawingBuffer: this.preserveDrawingBuffer }; this.gl = this.gl || canvas.getContext(\"webgl2\", glopt) || canvas.getContext(\"webgl\", glopt) || canvas.getContext(\"experimental-webgl\", glopt) ; for(let layer of Object.values(this.layers)) { layer.gl = this.gl; layer.clear(); if(layer.shader) layer.shader.restoreWebGL(this.gl); } this.prefetch(); this.emit('update'); } addLayer(id, layer) { layer.id = id; layer.addEvent('ready', () =&gt; { if(Object.values(this.layers).every( l =&gt; l.status == 'ready')) this.emit('ready'); this.prefetch(); }); layer.addEvent('update', () =&gt; { this.emit('update'); }); layer.addEvent('updateSize', () =&gt; { this.updateSize(); }); layer.gl = this.gl; layer.overlayElement = this.overlayElement; this.layers[id] = layer; this.prefetch(); } removeLayer(layer) { layer.clear(); //order is important. delete this.layers[layer.id]; delete Cache.layers[layer]; this.prefetch(); } updateSize() { const discardHidden = true; let sceneBBox = Layer.computeLayersBBox(this.layers, discardHidden); let minScale = Layer.computeLayersMinScale(this.layers, discardHidden); if (sceneBBox != null) this.camera.updateBounds(sceneBBox, minScale); this.emit('updateSize'); } draw(time) { let gl = this.gl; let view = this.camera.glViewport(); gl.viewport(view.x, view.y, view.dx, view.dy); var b = [0, 0, 0, 0]; gl.clearColor(b[0], b[1], b[2], b[3], b[4]); gl.clear(gl.COLOR_BUFFER_BIT); gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA); gl.enable(gl.BLEND); //TODO: getCurren shoudl redurn {position, done} let pos = this.camera.getGlCurrentTransform(time); //todo we could actually prefetch toward the future a little bit this.prefetch(pos); //pos layers using zindex. let ordered = Object.values(this.layers).sort( (a, b) =&gt; a.zindex - b.zindex); //NOTICE: camera(pos) must be relative to the WHOLE canvas let done = true; for(let layer of ordered) if(layer.visible) done = layer.draw(pos, view) &amp;&amp; done; //TODO not really an elegant solution to tell if we have reached the target, the check should be in getCurrentTransform. return done &amp;&amp; pos.t &gt;= this.camera.target.t; } /** * This function have each layer to check which tiles are needed and schedule them for download. * @param {object} transform is the camera position (layer will combine with local transform). */ prefetch(transform) { if(!transform) transform = this.camera.getGlCurrentTransform(performance.now()); for(let id in this.layers) { let layer = this.layers[id]; //console.log(layer); //console.log(layer.layout.status); if(layer.visible &amp;&amp; layer.status == 'ready') { layer.prefetch(transform, this.camera.glViewport()); } } } } export { Canvas } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Controller.js.html":{"id":"Controller.js.html","title":"Source: Controller.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Controller.js /** * Virtual nase class for controllers: classes that handle mouse and touch events and links to pan, zoom, etc. * Callbacks supporte are: * * *panStart(event)* calling event.preventDefault() will capture the panning gestire * * *panMove(event)* * * *panEnd(event)* * * *pinchStart(event)* calling event.preventDefault() will capture the pinch gestire * * *pinchMove(event)* * * *pinchEnd(event)* * * *wheelDelta(event)* * * *singleTap(event)* * * *wheelDelta(event)* * * *doubleTap(event)* * * *resize(event)* * * In general event.preventDefault() will capture the event and wont be propagated to other controllers. * * @param {options} options * * *panDelay* inertia of the movement in ms for panning movements (default 100) * * *zoomDelay* a zoom event is smoothed over this delay in ms (default 200) * * *priority* higher priority controllers are invoked in advance. */ class Controller { constructor(options) { /* For some reason can't define these variables static, for the moment just use the numeric value. static NoModifiers = 0; static CrtlModifier = 1; static ShiftModifier = 2; static AltModifier = 4; */ Object.assign(this, { active: true, debug: false, panDelay: 50, zoomDelay: 200, priority: 0, activeModifiers: [0] }); Object.assign(this, options); } modifierState(e) { let state = 0; if(e.ctrlKey) state += 1; if(e.shiftKey) state += 2; if(e.altKey) state += 4; return state; } captureEvents() { this.capture = true; //TODO should actually specify WHAT it is capturing: which touch etc. } releaseEvents() { this.capture = false; } /* Implement these functions to interacts with mouse/touch/resize events. */ } export { Controller } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Layer.js.html":{"id":"Layer.js.html","title":"Source: Layer.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Layer.js import { Transform } from './Transform.js' import { Layout } from './Layout.js' import { Cache } from './Cache.js' import { BoundingBox } from './BoundingBox.js' /** * @param {string} id unique id for layer. * @param {object} options * * *label*: * * *transform*: relative coordinate [transformation](#transform) from layer to canvas * * *visible*: where to render or not * * *zindex*: stack ordering of the layer higher on top * * *opacity*: from 0.0 to 1.0 (0.0 is fully transparent) * * *rasters*: [rasters](#raster) used for rendering. * * *controls*: shader parameters that can be modified (eg. light direction) * * *shader*: [shader](#shader) used for rendering * * *layout*: one of image, deepzoom, google, iiif, or zoomify * * *mipmapBias*: default 0.4, when to switch between different levels of the mipmap, 0 means switch as early * as the tile would be enlarged on the screen, while 1.0 means switch when 1 pixel in tile is &gt;= 2 pixels on screen * * *prefetchBorder*: border tiles prefetch (default 1) * * *maxRequest*: max number of simultaneous requests (should be GLOBAL not per layer!) default 4 */ class Layer { constructor(options) { //create from derived class if type specified if (options.type) { let type = options.type; delete options.type; if (type in this.types) { return this.types[type](options); } throw \"Layer type: \" + type + \" module has not been loaded\"; } this.init(options); /* //create members from options. this.rasters = this.rasters.map((raster) =&gt; new Raster(raster)); //layout needs to be the same for all rasters if(this.rasters.length) { if(typeof(this.layout) != 'object') this.layout = new Layout(this.rasters[0].url, this.layout) this.setLayout(this.layout) if(this.rasters.length) for(let raster in this.rasters) raster.layout = this.layout; } if(this.shader) this.shader = new Shader(this.shader); */ } init(options) { Object.assign(this, { transform: new Transform(), visible: true, zindex: 0, opacity: 1.0, overlay: false, //in the GUI it won't affect the visibility of the other layers rasters: [], layers: [], controls: {}, controllers: [], shaders: {}, layout: 'image', shader: null, //current shader. gl: null, prefetchBorder: 1, mipmapBias: 0.4, maxRequest: 4, signals: { update: [], ready: [], updateSize: [] }, //update callbacks for a redraw, ready once layout is known. //internal stuff, should not be passed as options. tiles: new Map(), //keep references to each texture (and status) indexed by level, x and y. //each tile is tex: [.. one for raster ..], missing: 3 missing tex before tile is ready. //only raster used by the shader will be loade. queue: [], //queue of tiles to be loaded. requested: {}, //tiles requested. }); Object.assign(this, options); this.transform = new Transform(this.transform); if (typeof (this.layout) == 'string') { let size = { width: this.width || 0, height: this.height || 0 }; this.setLayout(new Layout(null, this.layout, size)); } else { this.setLayout(this.layout); } } addEvent(event, callback) { this.signals[event].push(callback); } emit(event, ...parameters) { for (let r of this.signals[event]) r(...parameters); } setLayout(layout) { let callback = () =&gt; { this.status = 'ready'; this.setupTiles(); //setup expect status to be ready! this.emit('ready'); this.emit('update'); }; if (layout.status == 'ready') //layout already initialized. callback(); else layout.addEvent('ready', callback); this.layout = layout; // Set signal to acknowledge change of bbox when it is known. Let this signal go up to canvas this.layout.addEvent('updateSize', () =&gt; { this.emit('updateSize'); }); } setTransform(tx) { this.transform = tx; this.emit('updateSize'); } setShader(id) { if (!id in this.shaders) throw \"Unknown shader: \" + id; this.shader = this.shaders[id]; this.setupTiles(); this.shader.setEvent('update', () =&gt; { this.emit('update'); }); } getMode() { return this.shader.mode; } getModes() { if (this.shader) return this.shader.modes; return []; } setMode(mode) { this.shader.setMode(mode); this.emit('update'); } /** * @param {bool} visible */ setVisible(visible) { this.visible = visible; this.previouslyNeeded = null; this.emit('update'); } /** * @param {int} zindex */ setZindex(zindex) { this.zindex = zindex; this.emit('update'); } static computeLayersMinScale(layers, discardHidden) { if (layers == undefined || layers == null) { console.log(\"ASKING SCALE INFO ON NO LAYERS\"); return 1; } let layersScale = 1; for (let layer of Object.values(layers)) { if (!discardHidden || layer.visible) { let s = layer.scale(); layersScale = Math.min(layersScale, s); } } return layersScale; } scale() { // FIXME: this do not consider children layers return this.transform.z; } boundingBox() { // FIXME: this do not consider children layers // Take layout bbox let result = this.layout.boundingBox(); // Apply layer transform to bbox if (this.transform != null &amp;&amp; this.transform != undefined) { result = this.transform.transformBox(result); } return result; } static computeLayersBBox(layers, discardHidden) { if (layers == undefined || layers == null) { console.log(\"ASKING BBOX INFO ON NO LAYERS\"); let emptyBox = new BoundingBox(); return emptyBox; } let layersBbox = new BoundingBox(); for (let layer of Object.values(layers)) { if ((!discardHidden || layer.visible) &amp;&amp; layer.layout.width) { const bbox = layer.boundingBox(); layersBbox.mergeBox(bbox); } } return layersBbox; } setControl(name, value, dt) { let now = performance.now(); let control = this.controls[name]; this.interpolateControl(control, now); control.source.value = [...control.current.value]; control.source.t = now; control.target.value = [...value]; control.target.t = now + dt; this.emit('update'); } interpolateControls() { let now = performance.now(); let done = true; for (let control of Object.values(this.controls)) done = this.interpolateControl(control, now) &amp;&amp; done; return done; } interpolateControl(control, time) { let source = control.source; let target = control.target; let current = control.current; current.t = time; if (time &lt; source.t) { current.value = [...source.value]; return false; } if (time &gt; target.t - 0.0001) { let done = current.value.every((e, i) =&gt; e === target.value[i]); current.value = [...target.value]; return done; } let t = (target.t - source.t); let tt = (time - source.t) / t; let st = (target.t - time) / t; current.value = []; for (let i = 0; i &lt; source.value.length; i++) current.value[i] = (st * source.value[i] + tt * target.value[i]); return false; } dropTile(tile) { for(let i = 0; i &lt; tile.tex.length; i++) { if(tile.tex[i]) { this.gl.deleteTexture(tile.tex[i]); } } this.tiles.delete(tile.index); } clear() { this.ibuffer = this.vbuffer = null; Cache.flushLayer(this); this.tiles = new Map(); //TODO We need to drop these tile textures before clearing Map this.setupTiles(); this.queue = []; this.previouslyNeeded = false; } /** * render the */ draw(transform, viewport) { //exception for layout image where we still do not know the image size //how linear or srgb should be specified here. // gl.pixelStorei(gl.UNPACK_COLORSPACE_CONVERSION_WEBGL, gl.NONE); if (this.status != 'ready')// || this.tiles.size == 0) return true; if (!this.shader) throw \"Shader not specified!\"; let done = this.interpolateControls(); this.prepareWebGL(); // find which quads to draw and in case request for them transform = this.transform.compose(transform); let needed = this.layout.neededBox(viewport, transform, 0, this.mipmapBias); let torender = this.toRender(needed); let matrix = transform.projectionMatrix(viewport); this.gl.uniformMatrix4fv(this.shader.matrixlocation, this.gl.FALSE, matrix); for (let index in torender) { let tile = torender[index]; // if(tile.complete) this.drawTile(torender[index]); } // gl.uniform1f(t.opacitylocation, t.opacity); return done; } drawTile(tile) { let tiledata = this.tiles.get(tile.index); if (tiledata.missing != 0) throw \"Attempt to draw tile still missing textures\" //TODO might want to change the function to oaccept tile as argument let c = this.layout.tileCoords(tile.level, tile.x, tile.y); //update coords and texture buffers this.updateTileBuffers(c.coords, c.tcoords); //bind textures let gl = this.gl; for (var i = 0; i &lt; this.shader.samplers.length; i++) { let id = this.shader.samplers[i].id; gl.uniform1i(this.shader.samplers[i].location, i); gl.activeTexture(gl.TEXTURE0 + i); gl.bindTexture(gl.TEXTURE_2D, tiledata.tex[id]); } gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0); } /* given the full pyramid of needed tiles for a certain bounding box, * starts from the preferred levels and goes up in the hierarchy if a tile is missing. * complete is true if all of the 'brothers' in the hierarchy are loaded, * drawing incomplete tiles enhance the resolution early at the cost of some overdrawing and problems with opacity. */ toRender(needed) { let torender = {}; //array of minlevel, actual level, x, y (referred to minlevel) let brothers = {}; let minlevel = needed.level; let box = needed.pyramid[minlevel]; for (let y = box.yLow; y &lt; box.yHigh; y++) { for (let x = box.xLow; x &lt; box.xHigh; x++) { let level = minlevel; while (level &gt;= 0) { let d = minlevel - level; let index = this.layout.index(level, x &gt;&gt; d, y &gt;&gt; d); if (this.tiles.has(index) &amp;&amp; this.tiles.get(index).missing == 0) { torender[index] = { index: index, level: level, x: x &gt;&gt; d, y: y &gt;&gt; d, complete: true }; break; } else { let sx = (x &gt;&gt; (d + 1)) &lt;&lt; 1; let sy = (y &gt;&gt; (d + 1)) &lt;&lt; 1; brothers[this.layout.index(level, sx, sy)] = 1; brothers[this.layout.index(level, sx + 1, sy)] = 1; brothers[this.layout.index(level, sx + 1, sy + 1)] = 1; brothers[this.layout.index(level, sx, sy + 1)] = 1; } level--; } } } for (let index in brothers) { if (index in torender) torender[index].complete = false; } return torender; } updateTileBuffers(coords, tcoords) { let gl = this.gl; //TODO to reduce the number of calls (probably not needed) we can join buffers, and just make one call per draw! (except the bufferData, which is per node) gl.bindBuffer(gl.ARRAY_BUFFER, this.vbuffer); gl.bufferData(gl.ARRAY_BUFFER, coords, gl.STATIC_DRAW); gl.vertexAttribPointer(this.shader.coordattrib, 3, gl.FLOAT, false, 0, 0); gl.enableVertexAttribArray(this.shader.coordattrib); gl.bindBuffer(gl.ARRAY_BUFFER, this.tbuffer); gl.bufferData(gl.ARRAY_BUFFER, tcoords, gl.STATIC_DRAW); gl.vertexAttribPointer(this.shader.texattrib, 2, gl.FLOAT, false, 0, 0); gl.enableVertexAttribArray(this.shader.texattrib); } /** * If layout is ready and shader is assigned, creates or update tiles to keep track of what is missing. */ setupTiles() { if (!this.shader || !this.layout || this.layout.status != 'ready') return; // if(!this.tiles.size) { // this.tiles = JSON.parse(JSON.stringify(this.layout.tiles)); // for(let tile of this.tiles) { // tile.tex = new Array(this.shader.samplers.length); // tile.missing = this.shader.samplers.length; // tile.size = 0; // } // return; // } for (let tile of this.tiles) { tile.missing = this.shader.samplers.length;; for (let sampler of this.shader.samplers) { if (tile.tex[sampler.id]) tile.missing--; } } } prepareWebGL() { let gl = this.gl; if (!this.ibuffer) { //this part might go into another function. this.ibuffer = gl.createBuffer(); gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, this.ibuffer); gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array([3, 2, 1, 3, 1, 0]), gl.STATIC_DRAW); this.vbuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, this.vbuffer); gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0]), gl.STATIC_DRAW); this.tbuffer = gl.createBuffer(); gl.bindBuffer(gl.ARRAY_BUFFER, this.tbuffer); gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0, 0, 0, 1, 1, 1, 1, 0]), gl.STATIC_DRAW); } if (this.shader.needsUpdate) this.shader.createProgram(gl); gl.useProgram(this.shader.program); this.shader.updateUniforms(gl, this.shader.program); } sameNeeded(a, b) { if(a.level != b.level) return false; for(let p of ['xLow', 'xHigh', 'yLow', 'yHigh']) if(a.pyramid[a.level][p] != b.pyramid[a.level][p]) return false; return true; } /** * @param {object] transform is the canvas coordinate transformation * @param {viewport} is the viewport for the rendering, note: for lens might be different! Where we change it? here layer should know! */ prefetch(transform, viewport) { if (this.layers.length != 0) { //combine layers for (let layer of this.layers) layer.prefetch(transform, viewport); } if (this.rasters.length == 0) return; if (this.status != 'ready') return; if (typeof (this.layout) != 'object') throw \"AH!\"; let needed = this.layout.neededBox(viewport, transform, this.prefetchBorder, this.mipmapBias); if (this.previouslyNeeded &amp;&amp; this.sameNeeded(this.previouslyNeeded, needed)) return; this.previouslyNeeded = needed; this.queue = []; let now = performance.now(); //look for needed nodes and prefetched nodes (on the pos destination let missing = this.shader.samplers.length; for (let level = 0; level &lt;= needed.level; level++) { let box = needed.pyramid[level]; let tmp = []; for (let y = box.yLow; y &lt; box.yHigh; y++) { for (let x = box.xLow; x &lt; box.xHigh; x++) { let index = this.layout.index(level, x, y); let tile = this.tiles.get(index) || { index, x, y, missing, tex: [], level }; tile.time = now; tile.priority = needed.level - level; if (tile.missing != 0 &amp;&amp; !this.requested[index]) tmp.push(tile); } } let c = box.center(); //sort tiles by distance to the center TODO: check it's correct! tmp.sort(function (a, b) { return Math.abs(a.x - c[0]) + Math.abs(a.y - c[1]) - Math.abs(b.x - c[0]) - Math.abs(b.y - c[1]); }); this.queue = this.queue.concat(tmp); } Cache.setCandidates(this); } async loadTile(tile, callback) { if (this.tiles.has(tile.index)) throw \"AAARRGGHHH double tile!\"; if (this.requested[tile.index]) throw \"AAARRGGHHH double request!\"; this.tiles.set(tile.index, tile); this.requested[tile.index] = true; if (this.layout.type == 'itarzoom') { tile.url = this.layout.getTileURL(null, tile); let options = {}; if (tile.end) options.headers = { range: `bytes=${tile.start}-${tile.end}`, 'Accept-Encoding': 'indentity' } var response = await fetch(tile.url, options); if (!response.ok) { callback(\"Failed loading \" + tile.url + \": \" + response.statusText); return; } let blob = await response.blob(); let i = 0; for (let sampler of this.shader.samplers) { let raster = this.rasters[sampler.id]; let imgblob = blob.slice(tile.offsets[i], tile.offsets[i + 1]); const img = await raster.blobToImage(imgblob, this.gl); let tex = raster.loadTexture(this.gl, img); let size = img.width * img.height * 3; tile.size += size; tile.tex[sampler.id] = tex; i++; } tile.missing = 0; this.emit('update'); delete this.requested[tile.index]; if (callback) callback(tile.size); return; } for (let sampler of this.shader.samplers) { let raster = this.rasters[sampler.id]; tile.url = this.layout.getTileURL(sampler.id, tile); const [tex, size] = await raster.loadImage(tile, this.gl); if (this.layout.type == \"image\") { this.layout.width = raster.width; this.layout.height = raster.height; this.layout.initBoxes(); } tile.size += size; tile.tex[sampler.id] = tex; tile.missing--; if (tile.missing &lt;= 0) { this.emit('update'); delete this.requested[tile.index]; if (callback) callback(size); } } } } Layer.prototype.types = {} export { Layer } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerAnnotation.js.html":{"id":"LayerAnnotation.js.html","title":"Source: LayerAnnotation.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: LayerAnnotation.js import { Annotation } from './Annotation.js'; import { Layer } from './Layer.js' /** * SVG or OpenGL polygons/lines/points annotation layer * @param {object} options * * *svgURL*: url for the svg containing the annotations * * *svgXML*: svg string containing the annotatiosn * * *geometry*: TODO: should contain the areas/lines/points for OpenGL rendering * * *style*: css style for the annotation elements (shadow dom allows css to apply only to this layer) * * *annotations*: collection of annotations info: each annotations is id: { label, svg (optional), data (custom data) (TODO) */ class LayerAnnotation extends Layer { constructor(options) { options = Object.assign({ // geometry: null, //unused, might want to store here the quads/shapes for opengl rendering style: null, //straightforward for svg annotations, to be defined oro opengl rendering annotations: [], hoverable: false, //display info about annotation on mousehover. selected: new Set, overlay: true, annotationsListEntry: null, //TODO: horrible name for the interface list of annotations }, options); super(options); this.signals.selected = []; this.signals.loaded = []; if (typeof (this.annotations) == \"string\") { //assumes it is an URL (async () =&gt; { await this.loadAnnotations(this.annotations); })(); } } async loadAnnotations(url) { var response = await fetch(url); if(!response.ok) { this.status = \"Failed loading \" + this.url + \": \" + response.statusText; return; } this.annotations = await response.json(); if(this.annotations.status == 'error') { alert(\"Failed to load annotations: \" + this.annotations.msg); return; } //this.annotations = this.annotations.map(a =&gt; '@context' in a ? Annotation.fromJsonLd(a): a); this.annotations = this.annotations.map(a =&gt; new Annotation(a)); for(let a of this.annotations) if(a.publish != 1) a.visible = false; this.annotations.sort((a, b) =&gt; a.label.localeCompare(b.label)); if(this.annotationsListEntry) this.createAnnotationsList(); this.emit('update'); this.emit('ready'); this.emit('loaded'); } newAnnotation(annotation, selected = true) { if(!annotation) annotation = new Annotation(); this.annotations.push(annotation); let html = this.createAnnotationEntry(annotation); let template = document.createElement('template'); template.innerHTML = html.trim(); let list = this.annotationsListEntry.element.parentElement.querySelector('.openlime-list'); list.appendChild(template.content.firstChild); this.clearSelected(); this.setSelected(annotation); return annotation; } annotationsEntry() { return this.annotationsListEntry = { html: '', list: [], //will be filled later. classes: 'openlime-annotations', status: () =&gt; 'active', oncreate: () =&gt; { if(Array.isArray(this.annotations)) this.createAnnotationsList(); } } } createAnnotationsList() { let html =''; for(let a of this.annotations) { html += this.createAnnotationEntry(a); } let list = this.annotationsListEntry.element.parentElement.querySelector('.openlime-list'); list.innerHTML = html; list.addEventListener('click', (e) =&gt; { let svg = e.srcElement.closest('svg'); if(svg) { let entry = svg.closest('[data-annotation]') entry.classList.toggle('hidden'); let id = entry.getAttribute('data-annotation'); let anno = this.getAnnotationById(id); anno.visible = !anno.visible; anno.needsUpdate = true; this.emit('update'); } let id = e.srcElement.getAttribute('data-annotation'); if(id) { this.clearSelected(); let anno = this.getAnnotationById(id); this.setSelected(anno, true); } }); } createAnnotationEntry(a) { return `&lt;a href=\"#\" data-annotation=\"${a.id}\" class=\"openlime-entry ${a.visible == 0? 'hidden':''}\"&gt;${a.label || ''} &lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"openlime-eye\"&gt;&lt;path d=\"M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z\"&gt;&lt;/path&gt;&lt;circle cx=\"12\" cy=\"12\" r=\"3\"&gt;&lt;/circle&gt;&lt;/svg&gt; &lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"openlime-eye-off\"&gt;&lt;path d=\"M17.94 17.94A10.07 10.07 0 0 1 12 20c-7 0-11-8-11-8a18.45 18.45 0 0 1 5.06-5.94M9.9 4.24A9.12 9.12 0 0 1 12 4c7 0 11 8 11 8a18.5 18.5 0 0 1-2.16 3.19m-6.72-1.07a3 3 0 1 1-4.24-4.24\"&gt;&lt;/path&gt;&lt;line x1=\"1\" y1=\"1\" x2=\"23\" y2=\"23\"&gt;&lt;/line&gt;&lt;/svg&gt; &lt;/a&gt;`; } getAnnotationById(id) { for(const anno of this.annotations) if(anno.id == id) return anno; return null; } clearSelected() { this.annotationsListEntry.element.parentElement.querySelectorAll(`[data-annotation]`).forEach((e) =&gt; e.classList.remove('selected')); this.selected.clear(); } //set selected class for annotation setSelected(anno, on = true) { this.annotationsListEntry.element.parentElement.querySelector(`[data-annotation=\"${anno.id}\"]`).classList.toggle('selected', on); if(on) this.selected.add(anno.id); else this.selected.delete(anno.id); this.emit('selected', anno); } } export { LayerAnnotation } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerBRDF.js.html":{"id":"LayerBRDF.js.html","title":"Source: LayerBRDF.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: LayerBRDF.js import { Layer } from './Layer.js' import { Raster } from './Raster.js' import { ShaderBRDF } from './ShaderBRDF.js' /** * Extends {@link Layer}. * @param {options} options Same as {@link Layer}, but channels(ks,kd,normals,gloss) are required. */ class LayerBRDF extends Layer { constructor(options) { super(options); if(Object.keys(this.rasters).length != 0) throw \"Rasters options should be empty!\"; if(!this.channels) throw \"channels option is required\"; if(!this.channels.kd || !this.channels.normals) throw \"kd and normals channels are required\"; if(!this.colorspaces) { console.log(\"LayerBRDF: missing colorspaces: force both to linear\"); this.colorspaces['kd'] = 'linear'; this.colorspaces['ks'] = 'linear'; } let id = 0; let urls = []; let samplers = []; for (let c in this.channels) { let url = this.channels[c]; switch (c) { case 'kd': this.rasters.push(new Raster({ format: 'vec3', attribute: 'kd', colorspace: this.colorspaces['kd'] })); samplers.push({ 'id': id, 'name': 'uTexKd' }); break; case 'ks': this.rasters.push(new Raster({ format: 'vec3', attribute: 'ks', colorspace: this.colorspaces['ks'] })); samplers.push({ 'id': id, 'name': 'uTexKs' }); break; case 'normals': this.rasters.push(new Raster({ format: 'vec3', attribute: 'normals', colorspace: 'linear' })); samplers.push({ 'id': id, 'name': 'uTexNormals' }); break; case 'gloss': this.rasters.push(new Raster({ format: 'float', attribute: 'gloss', colorspace: 'linear' })); samplers.push({ 'id': id, 'name': 'uTexGloss' }); break; default: break; } urls[id] = url; id++; } this.layout.setUrls(urls); let now = performance.now(); this.controls['light'] = { source:{ value: [0, 0], t: now }, target:{ value:[0, 0], t:now }, current:{ value:[0, 0], t:now } }; const brightness = options.brightness ? options.brightness : 1.0; const gamma = options.gamma ? options.gamma : 2.2; const alphaLimits = options.alphaLimits ? options.alphaLimits : [0.01, 0.5]; let shader = new ShaderBRDF({ 'label': 'Rgb', 'samplers': samplers, 'colorspaces': this.colorspaces, 'brightness': brightness, 'gamma': gamma, 'alphaLimits': alphaLimits }); this.shaders['brdf'] = shader; this.setShader('brdf'); } setLight(light, dt) { let r2 = light[0]*light[0] + light[1]*light[1]; if (r2 &gt; 1.0) { let r = Math.sqrt(r2); light[0] /= r; light[1] /= r; r2 = 1.0; } light[2] = Math.sqrt(1-r2); this.setControl('light', light, dt); } interpolateControls() { let done = super.interpolateControls(); if(!done) { let light = this.controls['light'].current.value; let r2 = light[0]*light[0] + light[1]*light[1]; if (r2 &gt; 1.0) { light[0] /= r2; light[1] /= r2; r2 = 1.0; } light[2] = Math.sqrt(1-r2); //let z = Math.sqrt(1 - light[0]*light[0] - light[1]*light[1]); this.shader.setLight([light[0], light[1], light[2], 0]); } return done; } } Layer.prototype.types['brdf'] = (options) =&gt; { return new LayerBRDF(options); } export { LayerBRDF } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerCombiner.js.html":{"id":"LayerCombiner.js.html","title":"Source: LayerCombiner.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: LayerCombiner.js import { Layer } from './Layer.js' /** * Combines other layers (using a framebuffer) using a shader. Lens is an example. Extends {@link Layer}. * @param {options} options Same as {@link Layer}, but url and layout are required. */ class LayerCombiner extends Layer { constructor(options) { super(options); if(Object.keys(this.rasters).length != 0) throw \"Rasters options should be empty!\"; /* let shader = new ShaderCombiner({ 'label': 'Combiner', 'samplers': [{ id:0, name:'source1', type:'vec3' }, { id:1, name:'source2', type:'vec3' }], }); this.shaders = {'standard': shader }; this.setShader('standard'); */ //todo if layers check for importjson this.textures = []; this.framebuffers = []; this.status = 'ready'; } draw(transform, viewport) { for(let layer of this.layers) if(layer.status != 'ready') return; if(!this.shader) throw \"Shader not specified!\"; let w = viewport.dx; let h = viewport.dy; if(!this.framebuffers.length || this.layout.width != w || this.layout.height != h) { this.deleteFramebuffers(); this.layout.width = w; this.layout.height = h; this.createFramebuffers(); } let gl = this.gl; var b = [0, 0, 0, 0]; gl.clearColor(b[0], b[1], b[2], b[3]); //TODO optimize: render to texture ONLY if some parameters change! //provider di textures... max memory and reference counting. for(let i = 0; i &lt; this.layers.length; i++) { gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffers[i]); gl.clear(gl.COLOR_BUFFER_BIT); this.layers[i].draw(transform, {x:0, y:0, dx:w, dy:h, w:w, h:h}); gl.bindFramebuffer(gl.FRAMEBUFFER, null); } this.prepareWebGL(); for(let i = 0; i &lt; this.layers.length; i++) { gl.uniform1i(this.shader.samplers[i].location, i); gl.activeTexture(gl.TEXTURE0 + i); gl.bindTexture(gl.TEXTURE_2D, this.textures[i]); } this.updateTileBuffers( new Float32Array([-1, -1, 0, -1, 1, 0, 1, 1, 0, 1, -1, 0]), new Float32Array([ 0, 0, 0, 1, 1, 1, 1, 0])); gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT,0); } createFramebuffers() { let gl = this.gl; for(let i = 0; i &lt; this.layers.length; i++) { //TODO for thing like lens, we might want to create SMALLER textures for some layers. const texture = gl.createTexture(); gl.bindTexture(gl.TEXTURE_2D, texture); const level = 0; const internalFormat = gl.RGBA; const border = 0; const format = gl.RGBA; const type = gl.UNSIGNED_BYTE; gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, this.layout.width, this.layout.height, border, format, type, null); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE); const framebuffer = gl.createFramebuffer(); gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer); gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0); gl.bindFramebuffer(gl.FRAMEBUFFER, null); this.textures[i] = texture; this.framebuffers[i] = framebuffer; } } //TODO release textures and framebuffers deleteFramebuffers() { } boundingBox() { // Combiner ask the combination of all its children boxes // keeping the hidden, because they could be hidden, but revealed by the combiner const discardHidden = false; let result = Layer.computeLayersBBox(this.layers, discardHidden); if (this.transform != null &amp;&amp; this.transform != undefined) { result = this.transform.transformBox(result); } return result; } scale() { //Combiner ask the scale of all its children //keeping the hidden, because they could be hidden, but revealed by the combiner const discardHidden = false; let scale = Layer.computeLayersMinScale(this.layers, discardHidden); scale *= this.transform.z; return scale; } } Layer.prototype.types['combiner'] = (options) =&gt; { return new LayerCombiner(options); } export { LayerCombiner } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerImage.js.html":{"id":"LayerImage.js.html","title":"Source: LayerImage.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: LayerImage.js import { Layer } from './Layer.js' import { Raster } from './Raster.js' import { Shader } from './Shader.js' /** * Display a simple image. Extends {@link Layer}. * @param {options} options Same as {@link Layer}, but url and layout are required. */ class LayerImage extends Layer { constructor(options) { super(options); if(Object.keys(this.rasters).length != 0) throw \"Rasters options should be empty!\"; if(!this.url) throw \"Url option is required\"; this.layout.setUrls([this.url]); const rasterFormat = this.format != null ? this.format : 'vec4'; let raster = new Raster({ format: rasterFormat, attribute: 'kd', colorspace: 'sRGB' }); this.rasters.push(raster); let shader = new Shader({ 'label': 'Rgb', 'samplers': [{ id:0, name:'kd', type: rasterFormat }] }); shader.fragShaderSrc = function(gl) { let gl2 = !(gl instanceof WebGLRenderingContext); let str = `${gl2? '#version 300 es' : ''} precision highp float; precision highp int; uniform sampler2D kd; ${gl2? 'in' : 'varying'} vec2 v_texcoord; ${gl2? 'out' : ''} vec4 color; void main() { color = texture${gl2?'':'2D'}(kd, v_texcoord); ${gl2? '':'gl_FragColor = color;'} } `; return str; }; this.shaders = {'standard': shader }; this.setShader('standard'); } } Layer.prototype.types['image'] = (options) =&gt; { return new LayerImage(options); } export { LayerImage } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerLens.js.html":{"id":"LayerLens.js.html","title":"Source: LayerLens.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: LayerLens.js import { Layer } from './Layer.js' import {LayerCombiner} from './LayerCombiner.js' import {ShaderLens} from './ShaderLens.js' /** * options must contain one layer and lens = {x:, y:, r:, border: } */ class LayerLens extends LayerCombiner { constructor(options) { options = Object.assign({ overlay: true }, options); super(options); // Shader lens currently handles up to 2 layers let shader = new ShaderLens(); if (this.layers.length == 2) shader.setSecondLayerEnabled(true); this.shaders['lens'] = shader; this.setShader('lens'); this.startPos = [0, 0]; this.border = 2; let now = performance.now(); this.controls['center'] = { source:{ value: [0, 0], t: now }, target:{ value:[0, 0], t:now }, current:{ value:[0, 0], t:now } }; this.controls['radius'] = { source:{ value: [0, 0], t: now }, target:{ value:[0, 0], t:now }, current:{ value:[0, 0], t:now } }; this.setLens(0,0,this.radius,this.border); this.signals.draw = []; } setLens(x = 0, y = 0, r = 100, border = 10) { this.border = border; this.setCenter(x, y); this.setRadius(r); } setRadius(r, delayms = 100) { this.setControl('radius', [r, 0], delayms); } getRadius() { return this.controls['radius'].current.value[0]; } setCenter(x, y, delayms = 100) { this.setControl('center', [x, y], delayms); } getCurrentCenter() { return this.controls['center'].current.value; } getTargetCenter() { return this.controls['center'].target.value; } draw(transform, viewport) { let done = this.interpolateControls(); const vlens = this.getLensInViewportCoords(transform, viewport); this.shader.setLensUniforms(vlens, [viewport.w, viewport.h]); this.emit('draw'); super.draw(transform, viewport); return done; } getLensViewport(transform, viewport) { const lensC = this.getCurrentCenter(); const l = transform.sceneToViewportCoords(viewport, lensC); const r = this.getRadius() * transform.z; return {x: Math.floor(l[0]-r), y: Math.floor(l[1]-r), dx: Math.ceil(2*r), dy: Math.ceil(2*r), w:viewport.w, h:viewport.h}; } getLensInViewportCoords(transform, viewport) { const lensC = this.getCurrentCenter(); const c = transform.sceneToViewportCoords(viewport, lensC); const r = this.getRadius(); return [c[0], c[1], r * transform.z, this.border]; } } Layer.prototype.types['lens'] = (options) =&gt; { return new LayerLens(options); } export {LayerLens} Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerRTI.js.html":{"id":"LayerRTI.js.html","title":"Source: LayerRTI.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: LayerRTI.js import { Layer } from './Layer.js' import { Raster } from './Raster.js' import { ShaderRTI } from './ShaderRTI.js' import { Transform } from './Transform.js' /** * Extends {@link Layer}. * @param {options} options Same as {@link Layer}, but url and layout are required. * **url**: points to a relight format .json * **plane**: url for the first coefficient (plane_0), needed for IIIF and IIP (without /info.json) */ class LayerRTI extends Layer { constructor(options) { super(options); if(Object.keys(this.rasters).length != 0) throw \"Rasters options should be empty!\"; if(!this.url) throw \"Url option is required\"; // if(!this.layout) // this.layout = 'image'; // this.layout.setUrl(this.url); // this.setLayout(this.layout); this.shaders['rti'] = new ShaderRTI({ normals: this.normals }); this.setShader('rti'); let now = performance.now(); this.controls['light'] = { source:{ value: [0, 0], t: now }, target:{ value:[0, 0], t:now }, current:{ value:[0, 0], t:now } }; this.worldRotation = 0; //if the canvas or the layer rotate, light direction neeeds to be rotated too. if(this.url) this.loadJson(this.url); } imageUrl(url, plane) { let path = this.url.substring(0, this.url.lastIndexOf('/')+1); switch(this.layout.type) { case 'image': return path + plane + '.jpg'; break; case 'google': return path + plane; break; case 'deepzoom': return path + plane + '.dzi'; break; case 'tarzoom': return path + plane + '.tzi'; break; case 'itarzoom': return path + 'planes.tzi'; break; case 'zoomify': return path + plane + '/ImageProperties.xml'; break; //case 'iip': return this.plane.throw Error(\"Unimplemented\"); case 'iiif': throw Error(\"Unimplemented\"); default: throw Error(\"Unknown layout: \" + layout.type); } } /* * Alias for setControl * @param {Array} light light direction as an array [x, y] * @param {number} dt delay */ setLight(light, dt) { this.setControl('light', light, dt); } loadJson(url) { (async () =&gt; { var response = await fetch(this.url); if(!response.ok) { this.status = \"Failed loading \" + this.url + \": \" + response.statusText; return; } let json = await response.json(); this.shader.init(json); let urls = []; for(let p = 0; p &lt; this.shader.njpegs; p++) { let url = this.imageUrl(this.url, 'plane_' + p); urls.push(url); let raster = new Raster({ format: 'vec3', attribute: 'coeff', colorspace: 'linear' }); this.rasters.push(raster); } if(this.normals) { // ITARZOOM must include normals and currently has a limitation: loads the entire tile let url = this.imageUrl(this.url, 'normals'); urls.push(url); let raster = new Raster({ format: 'vec3', attribute: 'coeff', colorspace: 'linear' }); this.rasters.push(raster); } this.layout.setUrls(urls); })().catch(e =&gt; { console.log(e); this.status = e; }); } /* * Internal function: light control maps to light direction in the shader. */ interpolateControls() { let done = super.interpolateControls(); if(!done) { let light = this.controls['light'].current.value; //this.shader.setLight(light); let rotated = Transform.rotate(light[0], light[1], this.worldRotation*Math.PI); this.shader.setLight([rotated.x, rotated.y]); } return done; } draw(transform, viewport) { this.worldRotation = transform.a + this.transform.a; return super.draw(transform, viewport); } } Layer.prototype.types['rti'] = (options) =&gt; { return new LayerRTI(options); } export { LayerRTI } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerSvgAnnotation.js.html":{"id":"LayerSvgAnnotation.js.html","title":"Source: LayerSvgAnnotation.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: LayerSvgAnnotation.js import { Layer } from './Layer.js'; import { Annotation } from './Annotation.js'; import { LayerAnnotation } from './LayerAnnotation.js'; /** * SVG or OpenGL polygons/lines/points annotation layer * @param {object} options * * *svgURL*: url for the svg containing the annotations * * *svgXML*: svg string containing the annotatiosn * * *style*: css style for the annotation elements (shadow dom allows css to apply only to this layer) */ class LayerSvgAnnotation extends LayerAnnotation { constructor(options) { options = Object.assign({ svgURL: null, svgXML: null, overlayElement: null, //reference to canvas overlayElement. TODO: check if really needed. shadow: true, //svg attached as shadow node (so style apply svgElement: null, //the svg layer svgGroup: null, classes: { '': { stroke: '#000', label: '' }, } }, options); super(options); this.style += Object.entries(this.classes).map((g) =&gt; `[data-class=${g[0]}] { stroke:${g[1].stroke}; }`).join('\\n'); //this.createSVGElement(); //this.setLayout(this.layout); } createSVGElement() { this.svgElement = document.createElementNS('http://www.w3.org/2000/svg', 'svg'); this.svgElement.classList.add('openlime-svgoverlay'); this.svgGroup = document.createElementNS('http://www.w3.org/2000/svg', 'g'); this.svgElement.append(this.svgGroup); let root = this.overlayElement; if (this.shadow) root = this.overlayElement.attachShadow({ mode: \"open\" }); if (this.style) { const style = document.createElement('style'); style.textContent = this.style; root.append(style); } root.appendChild(this.svgElement); } /* unused for the moment!!! async loadSVG(url) { var response = await fetch(url); if (!response.ok) { this.status = \"Failed loading \" + this.url + \": \" + response.statusText; return; } let text = await response.text(); let parser = new DOMParser(); this.svgXML = parser.parseFromString(text, \"image/svg+xml\").documentElement; throw \"if viewbox is set in svgURL should it overwrite options.viewbox or viceversa?\" } */ setVisible(visible) { if (this.svgElement) this.svgElement.style.display = visible ? 'block' : 'none'; super.setVisible(visible); } clearSelected() { if (!this.svgElement) this.createSVGElement(); // return; this.svgGroup.querySelectorAll('[data-annotation]').forEach((e) =&gt; e.classList.remove('selected')); super.clearSelected(); } setSelected(anno, on = true) { for (let a of this.svgElement.querySelectorAll(`[data-annotation=\"${anno.id}\"]`)) a.classList.toggle('selected', on); super.setSelected(anno, on); } newAnnotation(annotation, selected = true) { let svg = createElement('svg'); if (!annotation) annotation = new Annotation({ element: svg, selector_type: 'SvgSelector' }); return super.newAnnotation(annotation, selected) } draw(transform, viewport) { if (!this.svgElement) return true; let t = this.transform.compose(transform); this.svgElement.setAttribute('viewBox', `${-viewport.w / 2} ${-viewport.h / 2} ${viewport.w} ${viewport.h}`); let c = this.boundingBox().corner(0); this.svgGroup.setAttribute(\"transform\", `translate(${t.x} ${t.y}) rotate(${-t.a} 0 0) scale(${t.z} ${t.z}) translate(${c[0]} ${c[1]})`); return true; } prefetch(transform) { if (!this.svgElement) this.createSVGElement(); if (!this.visible) return; if (this.status != 'ready') return; const bBox = this.boundingBox(); this.svgElement.setAttribute('viewBox', `${bBox.xLow} ${bBox.yLow} ${bBox.xHigh - bBox.xLow} ${bBox.yHigh - bBox.yLow}`); //find which annotations needs to be added to the ccanvas, some //indexing whould be used, for the moment we just iterate all of them. for (let anno of this.annotations) { //TODO check for class visibility and bbox culling (or maybe should go to prefetch?) if (!anno.ready &amp;&amp; typeof anno.svg == 'string') { let parser = new DOMParser(); let element = parser.parseFromString(anno.svg, \"image/svg+xml\").documentElement; anno.elements = [...element.children] anno.ready = true; /* } else if(this.svgXML) { a.svgElement = this.svgXML.querySelector(`#${a.id}`); if(!a.svgElement) throw Error(`Could not find element with id: ${id} in svg`); } */ } if (!anno.needsUpdate) continue; anno.needsUpdate = false; for (let e of this.svgGroup.querySelectorAll(`[data-annotation=\"${anno.id}\"]`)) e.remove(); if (!anno.visible) continue; //second time will be 0 elements, but we need to //store somewhere knowledge of which items in the scene and which still not. for (let child of anno.elements) { let c = child; //.cloneNode(true); c.setAttribute('data-annotation', anno.id); c.setAttribute('data-class', anno.class); //c.setAttribute('data-layer', this.id); c.classList.add('openlime-annotation'); if (this.selected.has(anno.id)) c.classList.add('selected'); this.svgGroup.appendChild(c); c.onpointerdown = (e) =&gt; { if (e.button == 0) { e.preventDefault(); e.stopPropagation(); if (this.onClick &amp;&amp; this.onClick(anno)) return; if (this.selected.has(anno.id)) return; this.clearSelected(); this.setSelected(anno, true); } } //utils /* let parser = new DOMParser(); let use = createElement('use', { 'xlink:href': '#' + a.id, 'stroke-width': 10, 'pointer-events': 'stroke' }); //let use = parser.parseFromString(`&lt;use xlink:href=\"${a.id}\" stroke-width=\"10\" pointer-events=\"stroke\"/&gt;`, \"image/svg+xml\"); this.svgGroup.appendChild(use); */ } } } } function createElement(tag, attributes) { let e = document.createElementNS('http://www.w3.org/2000/svg', tag); if (attributes) for (const [key, value] of Object.entries(attributes)) e.setAttribute(key, value); return e; } Layer.prototype.types['svg_annotations'] = (options) =&gt; { return new LayerSvgAnnotation(options); } export { LayerSvgAnnotation } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Layout.js.html":{"id":"Layout.js.html","title":"Source: Layout.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Layout.js import { BoundingBox } from \"./BoundingBox\"; /** * @param {string|Object} url URL of the image or the tiled config file, * @param {string} type select one among: &lt;image, {@link https://www.microimages.com/documentation/TechGuides/78googleMapsStruc.pdf google}, {@link https://docs.microsoft.com/en-us/previous-versions/windows/silverlight/dotnet-windows-silverlight/cc645077(v=vs.95)?redirectedfrom=MSDN deepzoom}, {@link http://www.zoomify.com/ZIFFileFormatSpecification.htm zoomify}, {@link https://iipimage.sourceforge.io/ iip}, {@link https://iiif.io/api/image/3.0/ iiif}&gt; */ class Layout { constructor(url, type, options) { Object.assign(this, { type: type, width: 0, height: 0, tilesize: 256, overlap: 0, nlevels: 1, //level 0 is the top, single tile level. suffix: 'jpg', qbox: [], //array of bounding box in tiles, one for mipmap bbox: [], //array of bounding box in pixels (w, h) urls: [], signals: { ready: [], updateSize: [] }, //callbacks when the layout is ready. status: null, subdomains: 'abc' }); if(options) Object.assign(this, options); if(typeof(url) == 'string') this.setUrls([url]); if(typeof(url) == 'object') Object.assign(this, url); } setUrls(urls) { this.urls = urls; (async () =&gt; { switch(this.type) { case 'image': await this.initImage(); break; // No Url needed case 'google': await this.initGoogle(); break; // No Url needed case 'deepzoom1px': await this.initDeepzoom(true); break; // urls[0] only needed case 'deepzoom': await this.initDeepzoom(false); break; // urls[0] only needed case 'zoomify': await this.initZoomify(); break; // urls[0] only needed case 'iiif': await this.initIIIF(); break; // urls[0] only needed case 'tarzoom': await this.initTarzoom(); break; // all urls needed case 'itarzoom': await this.initITarzoom(); break; // actually it has just one url } this.initBoxes(); this.status = 'ready'; this.emit('ready'); })().catch(e =&gt; { console.log(e); this.status = e; }); } addEvent(event, callback) { this.signals[event].push(callback); } emit(event) { for(let r of this.signals[event]) r(this); } isReady() { return this.status == 'ready' &amp;&amp; this.width &amp;&amp; this.height; } boundingBox() { if(!this.width) throw \"Layout not initialized still\"; return new BoundingBox({xLow:-this.width/2, yLow: -this.height/2, xHigh: this.width/2, yHigh: this.height/2}); } /** * Each tile is assigned an unique number. */ index(level, x, y) { let startindex = 0; for(let i = 0; i &lt; level; i++) startindex += this.qbox[i].xHigh*this.qbox[i].yHigh; return startindex + y*this.qbox[level].xHigh + x; } /* * Compute all the bounding boxes (this.bbox and this.qbox). * @return number of tiles in the dataset */ initBoxes() { this.qbox = []; //by level (0 is the bottom) this.bbox = []; var w = this.width; var h = this.height; if(this.type == 'image') { this.qbox[0] = new BoundingBox({xLow:0, yLow: 0, xHigh: 1, yHigh: 1}); this.bbox[0] = new BoundingBox({xLow:0, yLow: 0, xHigh: w, yHigh: h}); // Acknowledge bbox change (useful for knowing scene extension (at canvas level)) this.emit('updateSize'); return 1; } for(let level = this.nlevels - 1; level &gt;= 0; level--) { this.qbox[level] = new BoundingBox({xLow:0, yLow: 0, xHigh: 0, yHigh: 0}); this.bbox[level] = new BoundingBox({xLow:0, yLow: 0, xHigh: w, yHigh: h}); this.qbox[level].yHigh = Math.ceil(h/this.tilesize); this.qbox[level].xHigh = Math.ceil(w/this.tilesize); // for(let y = 0; y*this.tilesize &lt; h; y++) { // TODO replace with division // this.qbox[level].yHigh = y+1; // } // for (let x = 0; x * this.tilesize &lt; w; x++) { // this.qbox[level].xHigh = x + 1; // // tiles.push({level:level, x:x, y:y}); // } w &gt;&gt;&gt;= 1; h &gt;&gt;&gt;= 1; } // Acknowledge bbox (useful for knowing scene extension (at canvas level)) this.emit('updateSize'); } /** Return the coordinates of the tile (in [0, 0, w h] image coordinate system) and the texture coords associated. * */ tileCoords(level, x, y) { let w = this.width; let h = this.height; //careful: here y is inverted due to textures not being flipped on load (Firefox fault!). var tcoords = new Float32Array([0, 1, 0, 0, 1, 0, 1, 1]); if(this.type == \"image\") { return { coords: new Float32Array([-w/2, -h/2, 0, -w/2, h/2, 0, w/2, h/2, 0, w/2, -h/2, 0]), tcoords: tcoords }; } let coords = new Float32Array([0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0]); let ilevel = this.nlevels - 1 - level; let side = this.tilesize*(1&lt;&lt;(ilevel)); //tile size in imagespace let tx = side; let ty = side; if(side*(x+1) &gt; this.width) { tx = (this.width - side*x); if(this.type == 'google') tcoords[4] = tcoords[6] = tx/side; } if(side*(y+1) &gt; this.height) { ty = (this.height - side*y); if(this.type == 'google') tcoords[1] = tcoords[7] = ty/side; } var lx = this.qbox[level].xHigh-1; //last tile x pos, if so no overlap. var ly = this.qbox[level].yHigh-1; var over = this.overlap; if(over) { let dtx = over / (tx/(1&lt;&lt;ilevel) + (x==0?0:over) + (x==lx?0:over)); let dty = over / (ty/(1&lt;&lt;ilevel) + (y==0?0:over) + (y==ly?0:over)); tcoords[0] = tcoords[2] = (x==0? 0: dtx); tcoords[3] = tcoords[5] = (y==0? 0: dty); tcoords[4] = tcoords[6] = (x==lx? 1: 1 - dtx); tcoords[1] = tcoords[7] = (y==ly? 1: 1 - dty); } //flip Y coordinates //TODO cleanup this mess! let tmp = tcoords[1]; tcoords[1] = tcoords[7] = tcoords[3]; tcoords[3] = tcoords[5] = tmp; for(let i = 0; i &lt; coords.length; i+= 3) { coords[i] = coords[i] *tx + side*x - this.width/2; coords[i+1] = -coords[i+1]*ty - side*y + this.height/2; } return { coords: coords, tcoords: tcoords } } /** * Given a viewport and a transform computes the tiles needed for each level. * @param {array} viewport array with left, bottom, width, height * @param {border} border is radius (in tiles units) of prefetch * @returns {object} with level: the optimal level in the pyramid, pyramid: array of bounding boxes in tile units. */ neededBox(viewport, transform, border, bias) { if(this.type == \"image\") return { level:0, pyramid: [new BoundingBox({ xLow:0, yLow:0, xHigh:1, yHigh:1 })] }; //here we are computing with inverse levels; level 0 is the bottom! let iminlevel = Math.max(0, Math.min(Math.floor(-Math.log2(transform.z) + bias), this.nlevels-1)); let minlevel = this.nlevels-1-iminlevel; // let bbox = transform.getInverseBox(viewport); //find box in image coordinates where (0, 0) is in the upper left corner. bbox.shift(this.width/2, this.height/2); let pyramid = []; for(let level = 0; level &lt;= minlevel; level++) { let ilevel = this.nlevels -1 -level; let side = this.tilesize*Math.pow(2, ilevel); let qbox = new BoundingBox(bbox); qbox.quantize(side); //clamp! qbox.xLow = Math.max(qbox.xLow - border, this.qbox[level].xLow); qbox.yLow = Math.max(qbox.yLow - border, this.qbox[level].yLow); qbox.xHigh = Math.min(qbox.xHigh + border, this.qbox[level].xHigh); qbox.yHigh = Math.min(qbox.yHigh + border, this.qbox[level].yHigh); pyramid[level] = qbox; } return { level: minlevel, pyramid: pyramid }; } getTileURL(id, tile) { throw Error(\"Layout not defined or ready.\"); } /* * Witdh and height can be recovered once the image is downloaded. */ async initImage() { this.getTileURL = (rasterid, tile) =&gt; { return this.urls[rasterid]; } this.nlevels = 1; this.tilesize = 0; } /** * url points to the folder (without /) * width and height must be defined */ async initGoogle(callback) { if(!this.width || !this.height) throw \"Google rasters require to specify width and height\"; this.tilesize = 256; this.overlap = 0; let max = Math.max(this.width, this.height)/this.tilesize; this.nlevels = Math.ceil(Math.log(max) / Math.LN2) + 1; if( this.urls[0].includes('{')) { this.getTileURL = (rasterid, tile) =&gt; { let s = this.subdomains ? this.subdomains[Math.abs(tile.x + tile.y) % this.subdomains.length] : ''; let vars = {s, ...tile, z: tile.level}; return this.urls[rasterid].replace(/{(.+?)}/g,(match,p)=&gt; vars[p]); } } else this.getTileURL = (rasterid, tile) =&gt; { return this.urls[rasterid] + \"/\" + tile.level + \"/\" + tile.y + \"/\" + tile.x + '.' + this.suffix; }; } /** * Expects the url to point to .dzi config file */ async initDeepzoom(onepixel) { let url = this.urls[0]; var response = await fetch(url); if(!response.ok) { this.status = \"Failed loading \" + url + \": \" + response.statusText; throw new Error(this.status); } let text = await response.text(); let xml = (new window.DOMParser()).parseFromString(text, \"text/xml\"); let doc = xml.documentElement; this.suffix = doc.getAttribute('Format'); this.tilesize = parseInt(doc.getAttribute('TileSize')); this.overlap = parseInt(doc.getAttribute('Overlap')); let size = doc.querySelector('Size'); this.width = parseInt(size.getAttribute('Width')); this.height = parseInt(size.getAttribute('Height')); let max = Math.max(this.width, this.height)/this.tilesize; this.nlevels = Math.ceil(Math.log(max) / Math.LN2) + 1; this.urls = this.urls.map(url =&gt; url.substr(0, url.lastIndexOf(\".\")) + '_files/'); this.skiplevels = 0; if(onepixel) this.skiplevels = Math.ceil(Math.log(this.tilesize) / Math.LN2); this.getTileURL = (rasterid, tile) =&gt; { let url = this.urls[rasterid]; let level = tile.level + this.skiplevels; return url + level + '/' + tile.x + '_' + tile.y + '.' + this.suffix; }; } async initTarzoom() { this.tarzoom =[]; for (let url of this.urls) { var response = await fetch(url); if (!response.ok) { this.status = \"Failed loading \" + url + \": \" + response.statusText; throw new Error(this.status); } let json = await response.json(); json.url = url.substr(0, url.lastIndexOf(\".\")) + '.tzb'; Object.assign(this, json); this.tarzoom.push(json); } this.getTileURL = (rasterid, tile) =&gt; { const tar = this.tarzoom[rasterid]; tile.start = tar.offsets[tile.index]; tile.end = tar.offsets[tile.index+1]; return tar.url; }; } async initITarzoom() { const url = this.urls[0]; var response = await fetch(url); if(!response.ok) { this.status = \"Failed loading \" + url + \": \" + response.statusText; throw new Error(this.status); } let json = await response.json(); Object.assign(this, json); //suffix, tilesize, overlap, width, height, levels this.url = url.substr(0, url.lastIndexOf(\".\")) + '.tzb'; this.getTileURL = (rasterid, tile) =&gt; { let index = tile.index*this.stride; tile.start = this.offsets[index]; tile.end = this.offsets[index+this.stride]; tile.offsets = [] for(let i = 0; i &lt; this.stride+1; i++) tile.offsets.push(this.offsets[index + i] - tile.start); return this.url; }; } /** * Expects the url to point to ImageProperties.xml file. */ async initZoomify() { const url = this.urls[0]; this.overlap = 0; var response = await fetch(url); if(!response.ok) { this.status = \"Failed loading \" + url + \": \" + response.statusText; throw new Error(this.status); } let text = await response.text(); let xml = (new window.DOMParser()).parseFromString(text, \"text/xml\"); let doc = xml.documentElement; this.tilesize = parseInt(doc.getAttribute('TILESIZE')); this.width = parseInt(doc.getAttribute('WIDTH')); this.height = parseInt(doc.getAttribute('HEIGHT')); if(!this.tilesize || !this.height || !this.width) throw \"Missing parameter files for zoomify!\"; let max = Math.max(this.width, this.height)/this.tilesize; this.nlevels = Math.ceil(Math.log(max) / Math.LN2) + 1; this.getTileURL = (rasterid, tile) =&gt; { const tileUrl = this.urls[rasterid].substr(0, url.lastIndexOf(\"/\")); let group = tile.index &gt;&gt; 8; return tileUrl + \"/TileGroup\" + group + \"/\" + tile.level + \"-\" + tile.x + \"-\" + tile.y + \".\" + this.suffix; }; } async initIIIF() { const url = this.urls[0]; this.overlap = 0; var response = await fetch(url); if(!response.ok) { this.status = \"Failed loading \" + url + \": \" + response.statusText; throw new Error(this.status); } let info = await response.json(); this.width = info.width; this.height = info.height; this.nlevels = info.tiles[0].scaleFactors.length; this.tilesize = info.tiles[0].width; this.getTileURL = (rasterid, tile) =&gt; { const tileUrl = this.urls[rasterid].substr(0, url.lastIndexOf(\"/\")); let tw = this.tilesize; let ilevel = parseInt(this.nlevels - 1 - tile.level); let s = Math.pow(2, tile.level); //region parameters let xr = tile.x * tw * s; let yr = tile.y * tw * s; let wr = Math.min(tw * s, this.width - xr) let hr = Math.min(tw * s, this.height - yr); // pixel size parameters /ws,hs/ let ws = tw if (xr + tw*s &gt; this.width) ws = (this.width - xr + s - 1) / s let hs = tw if (yr + tw*s &gt; this.height) hs = (this.height - yr + s - 1) / s return `${tileUrl}/${xr},${yr},${wr},${hr}/${ws},${hs}/0/default.jpg`; }; } } export { Layout } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"OpenLIME.js.html":{"id":"OpenLIME.js.html","title":"Source: OpenLIME.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: OpenLIME.js import { Canvas } from './Canvas.js' import { Camera } from './Camera.js' import { Transform } from './Transform.js' import { Layer } from './Layer.js' import { LayerImage } from './LayerImage.js' import { LayerCombiner } from './LayerCombiner.js' import { Layout } from './Layout.js' import { Raster } from './Raster.js' import { Shader } from './Shader.js' import { ShaderCombiner } from './ShaderCombiner.js' import { Controller } from './Controller.js' import { ControllerPanZoom } from './ControllerPanZoom.js' import { PointerManager } from './PointerManager.js' /** @module OpenLIME */ /** * Manages an OpenLIME viewer functionality on a canvas * how do I write more substantial documentation. * * @param {div} div of the DOM or selector (es. '#canvasid'), or a canvas. * @param {string} options is a url to a JSON describing the viewer content * @param {object} options is a JSON describing the viewer content * * **animate**: default *true*, calls requestAnimation() and manages refresh. * * **background**: css style for background (overwrites css if present) * * @example * const lime = new OpenLIME.OpenLIME('.openlime'); * // .openlime is the class of a DIV element in the DOM. */ class OpenLIME { constructor(div, options) { Object.assign(this, { background: null, canvas: {}, controllers: [], camera: new Camera() }); if(typeof(div) == 'string') div = document.querySelector(div); if(!div) throw \"Missing element parameter\"; Object.assign(this, options); if(this.background) div.style.background = this.background; this.containerElement = div; this.canvasElement = div.querySelector('canvas'); if(!this.canvasElement) { this.canvasElement = document.createElement('canvas'); div.prepend(this.canvasElement); } this.overlayElement = document.createElement('div'); this.overlayElement.classList.add('openlime-overlay'); this.containerElement.appendChild(this.overlayElement); this.canvas = new Canvas(this.canvasElement, this.overlayElement, this.camera, this.canvas); this.canvas.addEvent('update', () =&gt; { this.redraw(); }); this.pointerManager = new PointerManager(this.overlayElement); this.canvasElement.addEventListener('contextmenu', (e) =&gt; { e.preventDefault(); return false; }); var resizeobserver = new ResizeObserver( entries =&gt; { for (let entry of entries) { this.resize(entry.contentRect.width, entry.contentRect.height); } }); resizeobserver.observe(this.canvasElement); this.resize(this.canvasElement.clientWidth, this.canvasElement.clientHeight); } /* Convenience function, it actually passes to Canvas */ addLayer(id, layer) { canvas.addLayer(id, layer); } /** * Resize the canvas (and the overlay) and triggers a redraw. */ resize(width, height) { // Test with retina display! width *= window.devicePixelRatio; height *= window.devicePixelRatio; this.canvasElement.width = width; this.canvasElement.height = height; this.camera.setViewport({x:0, y:0, dx:width, dy:height, w:width, h:height}); this.canvas.prefetch(); this.redraw(); } /** * * Schedule a drawing. */ redraw() { if(this.animaterequest) return; this.animaterequest = requestAnimationFrame( (time) =&gt; { this.draw(time); }); } /** * Do not call this if OpenLIME is animating, use redraw() * @param {time} time as in performance.now() */ draw(time) { if(!time) time = performance.now(); this.animaterequest = null; let viewport = this.camera.viewport; let transform = this.camera.getCurrentTransform(time); let done = this.canvas.draw(time); if(!done) this.redraw(); } } export { OpenLIME } export { Canvas, Camera, Transform } export { Layer, LayerImage, LayerCombiner } export { Layout } export { Raster } export { Shader, ShaderCombiner } export { ControllerPanZoom } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"PointerManager.js.html":{"id":"PointerManager.js.html","title":"Source: PointerManager.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: PointerManager.js /** * Manages handles simultaneous events from a target. * how do I write more substantial documentation. * * @param {div} target is the DOM element from which the events are generated * @param {object} options is a JSON describing the options * * **diagonal**: default *27*, the screen diagonal in inch */ class PointerManager { constructor(target, options) { this.target = target; Object.assign(this, { diagonal: 27, // Standard monitor 27\" pinchMaxInterval: 200 // in ms, fingerDown event max distance in time to trigger a pinch. }); if (options) Object.assign(this, options); this.currentPointers = []; this.eventObservers = new Map(); this.ppmm = PointerManager.getPPMM(this.diagonal); this.target.style.touchAction = \"none\"; this.target.addEventListener('pointerdown', (e) =&gt; this.handleEvent(e), false); this.target.addEventListener('pointermove', (e) =&gt; this.handleEvent(e), false); this.target.addEventListener('pointerup', (e) =&gt; this.handleEvent(e), false); this.target.addEventListener('pointercancel', (e) =&gt; this.handleEvent(e), false); this.target.addEventListener('wheel', (e) =&gt; this.handleEvent(e), false); } /////////////////////////////////////////////////////////// /// Constants static get ANYPOINTER() { return -1; } /////////////////////////////////////////////////////////// /// Utilities static splitStr(str) { return str.trim().split(/\\s+/g); } static getPPMM(diagonal) { // sqrt(w^2 + h^2) / diagonal / 1in return Math.round(Math.sqrt(screen.width **2 + screen.height **2) / diagonal / 25.4); } /////////////////////////////////////////////////////////// /// Class interface // register pointer handlers. on(eventTypes, obj, idx = PointerManager.ANYPOINTER) { eventTypes = PointerManager.splitStr(eventTypes); if (typeof (obj) == 'function') { obj = Object.fromEntries(eventTypes.map(e =&gt; [e, obj])); obj.priority = -1000; } eventTypes.forEach(eventType =&gt; { if (idx == PointerManager.ANYPOINTER) { this.broadcastOn(eventType, obj); } else { const p = this.currentPointers[idx]; if (!p) { throw new Error(\"Bad Index\"); } p.on(eventType, obj); } }); return obj; } // unregister pointer handlers off(eventTypes, callback, idx = PointerManager.ANYPOINTER) { if (idx == PointerManager.ANYPOINTER) { this.broadcastOff(eventTypes, callback); } else { PointerManager.splitStr(eventTypes).forEach(eventType =&gt; { const p = this.currentPointers[idx]; if (!p) { throw new Error(\"Bad Index\"); } p.off(eventType, callback); }); } } onEvent(handler) { const cb_properties = ['fingerHover', 'fingerSingleTap', 'fingerDoubleTap', 'fingerHold', 'mouseWheel']; if (!handler.hasOwnProperty('priority')) throw new Error(\"Event handler has not priority property\"); if (!cb_properties.some((e) =&gt; typeof (handler[e]) == 'function')) throw new Error(\"Event handler properties are wrong or missing\"); for (let e of cb_properties) if (typeof (handler[e]) == 'function') { this.on(e, handler); } if(handler.panStart) this.onPan(handler); if(handler.pinchStart) this.onPinch(handler); } onPan(handler) { const cb_properties = ['panStart', 'panMove', 'panEnd']; if (!handler.hasOwnProperty('priority')) throw new Error(\"Event handler has not priority property\"); if (!cb_properties.every((e) =&gt; typeof (handler[e]) == 'function')) throw new Error(\"Pan handler is missing one of this functions: panStart, panMove or panEnd\"); handler.fingerMovingStart = (e) =&gt; { handler.panStart(e); if (!e.defaultPrevented) return; this.on('fingerMoving', (e1) =&gt; { handler.panMove(e1); }, e.idx); this.on('fingerMovingEnd', (e2) =&gt; { handler.panEnd(e2); }, e.idx); } this.on('fingerMovingStart', handler); } onPinch(handler) { const cb_properties = ['pinchStart', 'pinchMove', 'pinchEnd']; if (!handler.hasOwnProperty('priority')) throw new Error(\"Event handler has not priority property\"); if (!cb_properties.every((e) =&gt; typeof (handler[e]) == 'function')) throw new Error(\"Pinch handler is missing one of this functions: pinchStart, pinchMove or pinchEnd\"); handler.fingerDown = (e1) =&gt; { //find other pointers not in moving status const filtered = this.currentPointers.filter(cp =&gt; cp &amp;&amp; cp.idx != e1.idx &amp;&amp; cp.status == cp.stateEnum.DETECT); if (filtered.length == 0) return; //for each pointer search for the last fingerDown event. const fingerDownEvents = []; for (let cp of filtered) { let down = null; for (let e of cp.eventHistory.toArray()) if (e.fingerType == 'fingerDown') down = e; if (down) fingerDownEvents.push(down); } //we start from the closest one //TODO maybe we should sort by distance instead. fingerDownEvents.sort((a, b) =&gt; b.timeStamp - a.timeStamp); for (let e2 of fingerDownEvents) { if (e1.timeStamp - e2.timeStamp &gt; this.pinchInterval) break; handler.pinchStart(e1, e2); if (!e1.defaultPrevented) break; clearTimeout(this.currentPointers[e1.idx].timeout); clearTimeout(this.currentPointers[e2.idx].timeout); this.on('fingerMovingStart', (e) =&gt; e.preventDefault(), e1.idx); //we need to capture this event (pan conflict) this.on('fingerMovingStart', (e) =&gt; e.preventDefault(), e2.idx); this.on('fingerMoving', (e) =&gt; e2 &amp;&amp; handler.pinchMove(e1 = e, e2), e1.idx); //we need to assign e1 and e2, to keep last position. this.on('fingerMoving', (e) =&gt; e1 &amp;&amp; handler.pinchMove(e1, e2 = e), e2.idx); this.on('fingerMovingEnd', (e) =&gt; { if (e2) handler.pinchEnd(e, e2); e1 = e2 = null; }, e1.idx); this.on('fingerMovingEnd', (e) =&gt; { if (e1) handler.pinchEnd(e1, e); e1 = e2 = null; }, e2.idx); break; } } this.on('fingerDown', handler); } /////////////////////////////////////////////////////////// /// Implementation stuff // register broadcast handlers broadcastOn(eventType, obj) { const handlers = this.eventObservers.get(eventType); if (handlers) handlers.push(obj); else this.eventObservers.set(eventType, [obj]); } // unregister broadcast handlers broadcastOff(eventTypes, obj) { PointerManager.splitStr(eventTypes).forEach(eventType =&gt; { if (this.eventObservers.has(eventType)) { if (!obj) { this.eventObservers.delete(eventType); } else { const handlers = this.eventObservers.get(eventType); const index = handlers.indexOf(obj); if (index &gt; -1) { handlers.splice(index, 1); } if (handlers.length == 0) { this.eventObservers.delete(eventType); } } } }); } // emit broadcast events broadcast(e) { if (!this.eventObservers.has(e.fingerType)) return; this.eventObservers.get(e.fingerType) .sort((a, b) =&gt; b.priority - a.priority) .every(obj =&gt; { obj[e.fingerType](e); return !e.defaultPrevented; }); // the first obj returning a defaultPrevented event breaks the every loop } addCurrPointer(cp) { let result = -1; for (let i = 0; i &lt; this.currentPointers.length &amp;&amp; result &lt; 0; i++) { if (this.currentPointers[i] == null) { result = i; } } if (result &lt; 0) { this.currentPointers.push(cp); result = this.currentPointers.length - 1; } else { this.currentPointers[result] = cp; } return result; } removeCurrPointer(index) { this.currentPointers[index] = null; while ((this.currentPointers.length &gt; 0) &amp;&amp; (this.currentPointers[this.currentPointers.length - 1] == null)) { this.currentPointers.pop(); } } handleEvent(e) { if (e.type == 'pointerdown') this.target.setPointerCapture(e.pointerId); if (e.type == 'pointercancel') console.log(e); let handled = false; for (let i = 0; i &lt; this.currentPointers.length &amp;&amp; !handled; i++) { const cp = this.currentPointers[i]; if (cp) { handled = cp.handleEvent(e); if (cp.isDone()) this.removeCurrPointer(i); } } if (!handled) { const cp = new SinglePointerHandler(this, e.pointerId, { ppmm: this.ppmm }); handled = cp.handleEvent(e); } //e.preventDefault(); } } class SinglePointerHandler { constructor(parent, pointerId, options) { this.parent = parent; this.pointerId = pointerId; Object.assign(this, { ppmm: 3, // 27in screen 1920x1080 = 3 ppmm }); if (options) Object.assign(this, options); this.eventHistory = new CircularBuffer(10); this.isActive = false; this.startTap = 0; this.threshold = 15; // 15mm this.eventObservers = new Map(); this.isDown = false; this.done = false; this.stateEnum = { IDLE: 0, DETECT: 1, HOVER: 2, MOVING_START: 3, MOVING: 4, MOVING_END: 5, HOLD: 6, TAPS_DETECT: 7, SINGLE_TAP: 8, DOUBLE_TAP_DETECT: 9, DOUBLE_TAP: 10, }; this.status = this.stateEnum.IDLE; this.timeout = null; this.holdTimeoutThreshold = 600; this.tapTimeoutThreshold = 100; this.oldDownPos = { clientX: 0, clientY: 0 }; this.movingThreshold = 1; // 1mm this.idx = this.parent.addCurrPointer(this); } /////////////////////////////////////////////////////////// /// Utilities static distance(x0, y0, x1, y1) { return Math.sqrt((x1 - x0) ** 2 + (y1 - y0) ** 2); } distanceMM(x0, y0, x1, y1) { return SinglePointerHandler.distance(x0, y0, x1, y1) / this.ppmm; } /////////////////////////////////////////////////////////// /// Class interface on(eventType, obj) { this.eventObservers.set(eventType, obj); } off(eventType) { if (this.eventObservers.has(eventType)) { this.eventObservers.delete(eventType); } } /////////////////////////////////////////////////////////// /// Implementation stuff addToHistory(e) { this.eventHistory.push(e); } prevPointerEvent() { return this.eventHistory.last(); } handlePointerDown(e) { this.startTap = e.timeStamp; } handlePointerUp(e) { const tapDuration = e.timeStamp - this.startTap; } isLikelySamePointer(e) { let result = this.pointerId == e.pointerId; if (!result &amp;&amp; !this.isDown &amp;&amp; e.type == \"pointerdown\") { const prevP = this.prevPointerEvent(); if (prevP) { result = (e.pointerType == prevP.pointerType) &amp;&amp; this.distanceMM(e.clientX, e.clientY, prevP.clientX, prevP.clientY) &lt; this.threshold; } } return result; } // emit+broadcast emit(e) { if (this.eventObservers.has(e.fingerType)) { this.eventObservers.get(e.fingerType)[e.fingerType](e); if (e.defaultPrevented) return; } this.parent.broadcast(e); } // output Event, speed is computed only on pointermove createOutputEvent(e, type) { const result = e; result.fingerType = type; result.originSrc = this.originSrc; result.speedX = 0; result.speedY = 0; result.idx = this.idx; const prevP = this.prevPointerEvent(); if (prevP &amp;&amp; (e.type == 'pointermove')) { const dt = result.timeStamp - prevP.timeStamp; if (dt &gt; 0) { result.speedX = (result.clientX - prevP.clientX) / dt * 1000.0; // px/s result.speedY = (result.clientY - prevP.clientY) / dt * 1000.0; // px/s } } return result; } // Finite State Machine processEvent(e) { let distance = 0; if (e.type == \"pointerdown\") { this.oldDownPos.clientX = e.clientX; this.oldDownPos.clientY = e.clientY; this.isDown = true; } if (e.type == \"pointerup\" || e.type == \"pointercancel\") this.isDown = false; if (e.type == \"pointermove\" &amp;&amp; this.isDown) { distance = this.distanceMM(e.clientX, e.clientY, this.oldDownPos.clientX, this.oldDownPos.clientY) } if (e.type == \"wheel\") { this.emit(this.createOutputEvent(e, 'mouseWheel')); return; } switch (this.status) { case this.stateEnum.HOVER: case this.stateEnum.IDLE: if (e.type == 'pointermove') { this.emit(this.createOutputEvent(e, 'fingerHover')); this.status = this.stateEnum.HOVER; this.originSrc = e.composedPath()[0]; } else if (e.type == 'pointerdown') { this.status = this.stateEnum.DETECT; this.emit(this.createOutputEvent(e, 'fingerDown')); if (e.defaultPrevented) { // An observer captured the fingerDown event this.status = this.stateEnum.MOVING; break; } this.originSrc = e.composedPath()[0]; this.timeout = setTimeout(() =&gt; { this.emit(this.createOutputEvent(e, 'fingerHold')); if(e.defaultPrevented) this.status = this.stateEnum.IDLE; }, this.holdTimeoutThreshold); } break; case this.stateEnum.DETECT: if (e.type == 'pointercancel') { /// For Firefox clearTimeout(this.timeout); this.status = this.stateEnum.IDLE; this.emit(this.createOutputEvent(e, 'fingerHold')); } else if (e.type == 'pointermove' &amp;&amp; distance &gt; this.movingThreshold) { clearTimeout(this.timeout); this.status = this.stateEnum.MOVING; this.emit(this.createOutputEvent(e, 'fingerMovingStart')); } else if (e.type == 'pointerup') { clearTimeout(this.timeout); this.status = this.stateEnum.TAPS_DETECT; this.timeout = setTimeout(() =&gt; { this.status = this.stateEnum.IDLE; this.emit(this.createOutputEvent(e, 'fingerSingleTap')); }, this.tapTimeoutThreshold); } break; case this.stateEnum.TAPS_DETECT: if (e.type == 'pointerdown') { clearTimeout(this.timeout); this.status = this.stateEnum.DOUBLE_TAP_DETECT; this.timeout = setTimeout(() =&gt; { this.emit(this.createOutputEvent(e, 'fingerHold')); if(e.defaultPrevented) this.status = this.stateEnum.IDLE; }, this.tapTimeoutThreshold); } else if (e.type == 'pointermove' &amp;&amp; distance &gt; this.movingThreshold) { clearTimeout(this.timeout); this.status = this.stateEnum.IDLE; this.emit(this.createOutputEvent(e, 'fingerHover')); } break; case this.stateEnum.DOUBLE_TAP_DETECT: if (e.type == 'pointerup' || e.type == 'pointercancel') { clearTimeout(this.timeout); this.status = this.stateEnum.IDLE; this.emit(this.createOutputEvent(e, 'fingerDoubleTap')); } break; case this.stateEnum.DOUBLE_TAP_DETECT: if (e.type == 'pointermove' &amp;&amp; distance &gt; this.movingThreshold) { this.status = this.stateEnum.MOVING; this.emit(this.createOutputEvent(e, 'fingerMovingStart')); } break; case this.stateEnum.MOVING: if (e.type == 'pointermove') { // Remain MOVING this.emit(this.createOutputEvent(e, 'fingerMoving')); } else if (e.type == 'pointerup' || e.type == 'pointercancel') { this.status = this.stateEnum.IDLE; this.emit(this.createOutputEvent(e, 'fingerMovingEnd')); } break; default: console.log(\"ERROR \" + this.status); console.log(e); break; } this.addToHistory(e); } handleEvent(e) { let result = false; if (this.isLikelySamePointer(e)) { this.pointerId = e.pointerId; //it's mine this.processEvent(e); result = true; } return result; } isDone() { return this.status == this.stateEnum.IDLE; } } class CircularBuffer { constructor(capacity) { if (typeof capacity != \"number\" || !Number.isInteger(capacity) || capacity &lt; 1) throw new TypeError(\"Invalid capacity\"); this.buffer = new Array(capacity); this.capacity = capacity; this.first = 0; this.size = 0; } clear() { this.first = 0; this.size = 0; } empty() { return this.size == 0; } size() { return this.size; } capacity() { return this.capacity; } first() { let result = null; if (this.size &gt; 0) result = this.buffer[this.first]; return result; } last() { let result = null; if (this.size &gt; 0) result = this.buffer[(this.first + this.size - 1) % this.capacity]; return result; } enqueue(v) { this.first = (this.first &gt; 0) ? this.first - 1 : this.first = this.capacity - 1; this.buffer[this.first] = v; if (this.size &lt; this.capacity) this.size++; } push(v) { if (this.size == this.capacity) { this.buffer[this.first] = v; this.first = (this.first + 1) % this.capacity; } else { this.buffer[(this.first + this.size) % this.capacity] = v; this.size++; } } dequeue() { if (this.size == 0) throw new RangeError(\"Dequeue on empty buffer\"); const v = this.buffer[(this.first + this.size - 1) % this.capacity]; this.size--; return v; } pop() { return this.dequeue(); } shift() { if (this.size == 0) throw new RangeError(\"Shift on empty buffer\"); const v = this.buffer[this.first]; if (this.first == this.capacity - 1) this.first = 0; else this.first++; this.size--; return v; } get(start, end) { if (this.size == 0 &amp;&amp; start == 0 &amp;&amp; (end == undefined || end == 0)) return []; if (typeof start != \"number\" || !Number.isInteger(start) || start &lt; 0) throw new TypeError(\"Invalid start value\"); if (start &gt;= this.size) throw new RangeError(\"Start index past end of buffer: \" + start); if (end == undefined) return this.buffer[(this.first + start) % this.capacity]; if (typeof end != \"number\" || !Number.isInteger(end) || end &lt; 0) throw new TypeError(\"Invalid end value\"); if (end &gt;= this.size) throw new RangeError(\"End index past end of buffer: \" + end); if (this.first + start &gt;= this.capacity) { start -= this.capacity; end -= this.capacity; } if (this.first + end &lt; this.capacity) return this.buffer.slice(this.first + start, this.first + end + 1); else return this.buffer.slice(this.first + start, this.capacity).concat(this.buffer.slice(0, this.first + end + 1 - this.capacity)); } toArray() { if (this.size == 0) return []; return this.get(0, this.size - 1); } } export { PointerManager } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Raster.js.html":{"id":"Raster.js.html","title":"Source: Raster.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Raster.js /** * Raster is a providers of images and planes of coefficies. * It support all files format supported by browser and a set of tiled formats. * * Layout can be: * * image: a single image (.jpg, .png etc.) * * google: there is no config file, so layout, suffix is mandatory if not .jpg, and url is the base folder of the tiles. * * deepzoom: requires only url, can be autodetected from the extension (.dzi) * * zoomify: requires url, can be autodetected, from the ImageProperties.xml, suffix is required if not .jpg * * iip: requires url, can be autodetected from the url * * iiif: layout is mandatory, url should point to base url {scheme}://{server}{/prefix}/{identifier} * * @param {string} id an unique id for each raster * @param {url} url of the content * @param {object} options * * *type*: vec3 (default value) for standard images, vec4 when including alpha, vec2, float other purpouses. * * *attribute*: &lt;coeff|kd|ks|gloss|normals|dem&gt; meaning of the image. * * *colorSpace*: &lt;linear|srgb&gt; colorspace used for rendering. */ class Raster { constructor(options) { Object.assign(this, { format: 'vec3', colorSpace: 'linear', attribute: 'kd' }); Object.assign(this, options); } async loadImage(tile, gl) { let img; let cors = (new URL(tile.url, window.location.href)).origin !== window.location.origin; if (tile.end || typeof createImageBitmap == 'undefined') { let options = {}; options.headers = { range: `bytes=${tile.start}-${tile.end}`, 'Accept-Encoding': 'indentity', mode: cors? 'cors' : 'same-origin' }; let response = await fetch(tile.url, options); if (!response.ok) { callback(\"Failed loading \" + tile.url + \": \" + response.statusText); return; } if (response.status != 206) throw \"The server doesn't support partial content requests (206).\"; let blob = await response.blob(); img = await this.blobToImage(blob, gl); } else { img = document.createElement('img'); if (cors) img.crossOrigin=\"\"; img.onerror = function (e) { console.log(\"Texture loading error!\"); }; img.src = tile.url; await new Promise((resolve, reject) =&gt; { img.onload = () =&gt; resolve() }); } let tex = this.loadTexture(gl, img); //TODO 3 is not accurate for type of image, when changing from rgb to grayscale, fix this value. let size = img.width * img.height * 3; return [tex, size]; } async blobToImage(blob, gl) { let tex, img; if(typeof createImageBitmap != 'undefined') { var isFirefox = typeof InstallTrigger !== 'undefined'; //firefox does not support options for this call, BUT the image is automatically flipped. if(isFirefox) img = await createImageBitmap(blob); else img = await createImageBitmap(blob, { imageOrientation1: 'flipY' }); } else { //fallback for IOS let urlCreator = window.URL || window.webkitURL; img = document.createElement('img'); img.onerror = function(e) { console.log(\"Texture loading error!\"); }; img.src = urlCreator.createObjectURL(blob); await new Promise((resolve, reject) =&gt; { img.onload = () =&gt; resolve() }); urlCreator.revokeObjectURL(img.src); } return img; } /* * @param {function} callback as function(tex, sizeinBytes) */ loadTexture(gl, img) { this.width = img.width; //this will be useful for layout image. this.height = img.height; var tex = gl.createTexture(); gl.bindTexture(gl.TEXTURE_2D, tex); gl.texParameterf(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR); gl.texParameterf(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR); //_MIPMAP_LINEAR); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE); let glFormat = gl.RGBA; switch(this.format) { case 'vec3': glFormat = gl.RGB; break; case 'vec4': glFormat = gl.RGBA; break; case 'float': glFormat = gl.LUMINANCE; break; default: break; } gl.texImage2D(gl.TEXTURE_2D, 0, glFormat, glFormat, gl.UNSIGNED_BYTE, img); return tex; } } export { Raster } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Shader.js.html":{"id":"Shader.js.html","title":"Source: Shader.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Shader.js /** * @param {object} options * *label*: used for menu * *samplers*: array of rasters {id:, type: } color, normals, etc. * *uniforms*: type = &lt;vec4|vec3|vec2|float|int&gt;, needsUpdate controls when updated in gl, size is unused, value is and array or a float, * we also want to support interpolation: source (value is the target), start, end are the timing (same as camera interpolation) * *body*: code actually performing the rendering, needs to return a vec4 * *name*: name of the body function */ class Shader { constructor(options) { Object.assign(this, { version: 100, //check for webglversion. samplers: [], uniforms: {}, name: \"\", program: null, //webgl program modes: [], needsUpdate: true, signals: { 'update':[] } }); Object.assign(this, options); } setEvent(event, callback) { this.signals[event] = [callback]; } emit(event) { for(let r of this.signals[event]) r(this); } restoreWebGL(gl) { this.createProgram(gl); } setUniform(name, value) { let u = this.uniforms[name]; if(typeof(value) == \"number\" &amp;&amp; u.value == value) return; if(Array.isArray(value) &amp;&amp; Array.isArray(u.value) &amp;&amp; value.length == u.value.length) { let equal = true; for(let i = 0; i &lt; value.length; i++) if(value[i] != u.value[i]) { equal = false; break; } if(equal) return; } u.value = value; u.needsUpdate = true; this.emit('update'); } createProgram(gl) { let vert = gl.createShader(gl.VERTEX_SHADER); gl.shaderSource(vert, this.vertShaderSrc(gl)); gl.compileShader(vert); let compiled = gl.getShaderParameter(vert, gl.COMPILE_STATUS); if(!compiled) { console.log(gl.getShaderInfoLog(vert)); throw Error(\"Failed vertex shader compilation: see console log and ask for support.\"); } let frag = gl.createShader(gl.FRAGMENT_SHADER); gl.shaderSource(frag, this.fragShaderSrc(gl)); gl.compileShader(frag); if(this.program) gl.deleteProgram(this.program); let program = gl.createProgram(); gl.getShaderParameter(frag, gl.COMPILE_STATUS); compiled = gl.getShaderParameter(frag, gl.COMPILE_STATUS); if(!compiled) { console.log(this.fragShaderSrc()) console.log(gl.getShaderInfoLog(frag)); throw Error(\"Failed fragment shader compilation: see console log and ask for support.\"); } gl.attachShader(program, vert); gl.attachShader(program, frag); gl.linkProgram(program); if ( !gl.getProgramParameter( program, gl.LINK_STATUS) ) { var info = gl.getProgramInfoLog(program); throw new Error('Could not compile WebGL program. \\n\\n' + info); } //sampler units; for(let sampler of this.samplers) sampler.location = gl.getUniformLocation(program, sampler.name); this.coordattrib = gl.getAttribLocation(program, \"a_position\"); gl.vertexAttribPointer(this.coordattrib, 3, gl.FLOAT, false, 0, 0); gl.enableVertexAttribArray(this.coordattrib); this.texattrib = gl.getAttribLocation(program, \"a_texcoord\"); gl.vertexAttribPointer(this.texattrib, 2, gl.FLOAT, false, 0, 0); gl.enableVertexAttribArray(this.texattrib); this.matrixlocation = gl.getUniformLocation(program, \"u_matrix\"); this.program = program; this.needsUpdate = false; for(let uniform of Object.values(this.uniforms)) { uniform.location = null; uniform.needsUpdate = true; } } updateUniforms(gl, program) { let now = performance.now(); for(const [name, uniform] of Object.entries(this.uniforms)) { if(!uniform.location) uniform.location = gl.getUniformLocation(program, name); if(!uniform.location) //uniform not used in program continue; if(uniform.needsUpdate) { let value = uniform.value; switch(uniform.type) { case 'vec4': gl.uniform4fv(uniform.location, value); break; case 'vec3': gl.uniform3fv(uniform.location, value); break; case 'vec2': gl.uniform2fv(uniform.location, value); break; case 'float': gl.uniform1f(uniform.location, value); break; case 'int': gl.uniform1i (uniform.location, value); break; default: throw Error('Unknown uniform type: ' + u.type); } } } } vertShaderSrc(gl) { let gl2 = !(gl instanceof WebGLRenderingContext); return `${gl2? '#version 300 es':''} precision highp float; precision highp int; uniform mat4 u_matrix; ${gl2? 'in' : 'attribute'} vec4 a_position; ${gl2? 'in' : 'attribute'} vec2 a_texcoord; ${gl2? 'out' : 'varying'} vec2 v_texcoord; void main() { gl_Position = u_matrix * a_position; v_texcoord = a_texcoord; }`; } fragShaderSrc(gl) { throw 'Unimplemented!' } } export { Shader } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"ShaderBRDF.js.html":{"id":"ShaderBRDF.js.html","title":"Source: ShaderBRDF.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: ShaderBRDF.js import { Shader } from './Shader.js' /** * @param {object} options * mode: default is ward, can be [ward, diffuse, specular, normals] */ class ShaderBRDF extends Shader { constructor(options) { super({}); this.modes = ['ward', 'diffuse', 'specular', 'normals']; this.mode = 'ward'; Object.assign(this, options); const kdCS = this.colorspaces['kd'] == 'linear' ? 0 : 1; const ksCS = this.colorspaces['ks'] == 'linear' ? 0 : 1; const brightness = options.brightness ? options.brightness : 1.0; const gamma = options.gamma ? options.gamma : 2.2; const alphaLimits = options.alphaLimits ? options.alphaLimits : [0.01, 0.5]; this.uniforms = { uLightInfo: { type: 'vec4', needsUpdate: true, size: 4, value: [0.1, 0.1, 0.9, 0] }, uAlphaLimits: { type: 'vec2', needsUpdate: true, size: 2, value: alphaLimits }, uBrightnessGamma: { type: 'vec2', needsUpdate: true, size: 2, value: [brightness, gamma] }, uInputColorSpaceKd: { type: 'int', needsUpdate: true, size: 1, value: kdCS }, uInputColorSpaceKs: { type: 'int', needsUpdate: true, size: 1, value: ksCS }, } this.innerCode = ''; this.setMode(this.mode); } setLight(light) { // Light with 4 components (Spot: 4th==1, Dir: 4th==0) this.setUniform('uLightInfo', light); } setMode(mode) { this.mode = mode; switch(mode) { case 'ward': this.innerCode = `vec3 linearColor = (kd + ks * spec) * NdotL; linearColor += kd * 0.02; // HACK! adding just a bit of ambient` break; case 'diffuse': this.innerCode = `vec3 linearColor = kd;` break; case 'specular': this.innerCode = `vec3 linearColor = clamp((ks * spec) * NdotL, 0.0, 1.0);` break; case 'normals': this.innerCode = `vec3 linearColor = (N+vec3(1.))/2.; applyGamma = false;` break; default: console.log(\"ShaderBRDF: Unknown mode: \" + mode); throw Error(\"ShaderBRDF: Unknown mode: \" + mode); break; } this.needsUpdate = true; } fragShaderSrc(gl) { let gl2 = !(gl instanceof WebGLRenderingContext); let hasGloss = this.samplers.findIndex( s =&gt; s.name == 'uTexGloss') != -1; let hasKs = this.samplers.findIndex( s =&gt; s.name == 'uTexKs') != -1; let str = `${gl2? '#version 300 es' : ''} precision highp float; precision highp int; #define NULL_NORMAL vec3(0,0,0) #define SQR(x) ((x)*(x)) #define PI (3.14159265359) #define ISO_WARD_EXPONENT (4.0) ${gl2? 'in' : 'varying'} vec2 v_texcoord; uniform sampler2D uTexKd; uniform sampler2D uTexKs; uniform sampler2D uTexNormals; uniform sampler2D uTexGloss; uniform vec4 uLightInfo; // [x,y,z,w] (if .w==0 =&gt; Directional, if w==1 =&gt; Spot) uniform vec2 uAlphaLimits; uniform vec2 uBrightnessGamma; uniform int uInputColorSpaceKd; // 0: Linear; 1: sRGB uniform int uInputColorSpaceKs; // 0: Linear; 1: sRGB ${gl2? 'out' : ''} vec4 color; vec3 getNormal(const in vec2 texCoord) { vec3 n = texture(uTexNormals, texCoord).xyz; n = 2. * n - vec3(1.); float norm = length(n); if(norm &lt; 0.5) return NULL_NORMAL; else return n/norm; } vec3 linear2sRGB(vec3 linearRGB) { bvec3 cutoff = lessThan(linearRGB, vec3(0.0031308)); vec3 higher = vec3(1.055)*pow(linearRGB, vec3(1.0/2.4)) - vec3(0.055); vec3 lower = linearRGB * vec3(12.92); return mix(higher, lower, cutoff); } vec3 sRGB2Linear(vec3 sRGB) { bvec3 cutoff = lessThan(sRGB, vec3(0.04045)); vec3 higher = pow((sRGB + vec3(0.055))/vec3(1.055), vec3(2.4)); vec3 lower = sRGB/vec3(12.92); return mix(higher, lower, cutoff); } float ward(in vec3 V, in vec3 L, in vec3 N, in vec3 X, in vec3 Y, in float alpha) { vec3 H = normalize(V + L); float H_dot_N = dot(H, N); float sqr_alpha_H_dot_N = SQR(alpha * H_dot_N); if(sqr_alpha_H_dot_N &lt; 0.00001) return 0.0; float L_dot_N_mult_N_dot_V = dot(L,N) * dot(N,V); if(L_dot_N_mult_N_dot_V &lt;= 0.0) return 0.0; float spec = 1.0 / (4.0 * PI * alpha * alpha * sqrt(L_dot_N_mult_N_dot_V)); //float exponent = -(SQR(dot(H,X)) + SQR(dot(H,Y))) / sqr_alpha_H_dot_N; // Anisotropic float exponent = -SQR(tan(acos(H_dot_N))) / SQR(alpha); // Isotropic spec *= exp( exponent ); return spec; } void main() { vec3 N = getNormal(v_texcoord); if(N == NULL_NORMAL) { color = vec4(0.0); return; } vec3 L = (uLightInfo.w == 0.0) ? normalize(uLightInfo.xyz) : normalize(uLightInfo.xyz - gl_FragCoord.xyz); vec3 V = vec3(0.0,0.0,1.0); vec3 H = normalize(L + V); float NdotL = max(dot(N,L),0.0); vec3 kd = texture(uTexKd, v_texcoord).xyz; vec3 ks = ${hasKs ? 'texture(uTexKs, v_texcoord).xyz' : 'vec3(0.0, 0.0, 0.0)'}; if(uInputColorSpaceKd == 1) { kd = sRGB2Linear(kd); } if(uInputColorSpaceKs == 1) { ks = sRGB2Linear(ks); } kd /= PI; float gloss = ${hasGloss ? 'texture(uTexGloss, v_texcoord).x' : '0.0'}; float minGloss = 1.0 - pow(uAlphaLimits[1], 1.0 / ISO_WARD_EXPONENT); float maxGloss = 1.0 - pow(uAlphaLimits[0], 1.0 / ISO_WARD_EXPONENT); float alpha = pow(1.0 - gloss * (maxGloss - minGloss) - minGloss, ISO_WARD_EXPONENT); vec3 e = vec3(0.0,0.0,1.0); vec3 T = normalize(cross(N,e)); vec3 B = normalize(cross(N,T)); float spec = ward(V, L, N, T, B, alpha); bool applyGamma = true; ${this.innerCode} vec3 finalColor = applyGamma ? pow(linearColor * uBrightnessGamma[0], vec3(1.0/uBrightnessGamma[1])) : linearColor; color = vec4(finalColor, 1.0); ${gl2?'':'gl_FragColor = color;'} } `; return str; } } export { ShaderBRDF } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"ShaderCombiner.js.html":{"id":"ShaderCombiner.js.html","title":"Source: ShaderCombiner.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: ShaderCombiner.js import { Shader } from './Shader.js' /** * @param {object} options * *compose*: compose operation: add, subtract, multiply, etc. */ class ShaderCombiner extends Shader { constructor(options) { super(options); this.mode = 'mean', //Lighten Darken Contrast Inversion HSV components LCh components this.samplers = [ { id:0, name:'source1', type:'vec3' }, { id:1, name:'source2', type:'vec3' } ]; this.modes = ['first','second','mean','diff']; this.operations = { 'first': 'color = c1;', 'second': 'color = c2;', 'mean': 'color = (c1 + c2)/2.0;', 'diff': 'color = vec4(c2.rgb - c1.rgb, c1.a);' }; } setMode(mode) { // if(!(mode in this.modes)) if(this.modes.indexOf(mode)==-1) throw Error(\"Unknown mode: \" + mode); this.mode = mode; this.needsUpdate = true; } fragShaderSrc(gl) { let gl2 = !(gl instanceof WebGLRenderingContext); let operation = this.operations[this.mode]; return `${gl2? '#version 300 es' : ''} precision highp float; precision highp int; ${gl2? 'in' : 'varying'} vec2 v_texcoord; uniform sampler2D source1; uniform sampler2D source2; ${gl2? 'out' : ''} vec4 color; void main() { vec4 c1 = texture(source1, v_texcoord); vec4 c2 = texture(source2, v_texcoord); ${operation}; ${gl2?'':'gl_FragColor = color;'} } `; } vertShaderSrc(gl) { let gl2 = !(gl instanceof WebGLRenderingContext); return `${gl2? '#version 300 es':''} precision highp float; precision highp int; ${gl2? 'in' : 'attribute'} vec4 a_position; ${gl2? 'in' : 'attribute'} vec2 a_texcoord; ${gl2? 'out' : 'varying'} vec2 v_texcoord; void main() { gl_Position = a_position; v_texcoord = a_texcoord; }`; } } export { ShaderCombiner } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"ShaderRTI.js.html":{"id":"ShaderRTI.js.html","title":"Source: ShaderRTI.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: ShaderRTI.js import { Shader } from './Shader.js' /** * @param {object} options * *compose*: compose operation: add, subtract, multiply, etc. */ class ShaderRTI extends Shader { constructor(options) { super({}); Object.assign(this, { modes: ['light', 'normals', 'diffuse', 'specular'], mode: 'normal', type: ['ptm', 'hsh', 'sh', 'rbf', 'bln'], colorspaces: ['lrgb', 'rgb', 'mrgb', 'mycc'], nplanes: null, //number of coefficient planes yccplanes: null, //number of luminance planes for mycc color space njpegs: null, //number of textures needed (ceil(nplanes/3)) material: null, //material parameters lights: null, //light directions (needed for rbf interpolation) sigma: null, //rbf interpolation parameter ndimensions: null, //PCA dimension space (for rbf and bln) scale: null, //factor and bias are used to dequantize coefficient planes. bias: null, basis: null, //PCA basis for rbf and bln lweights: null //light direction dependent coefficients to be used with coefficient planes }); Object.assign(this, options); if(this.relight) this.init(this.relight); this.setMode('light'); } setMode(mode) { if(!(this.modes.includes(mode))) throw Error(\"Unknown mode: \" + mode); this.mode = mode; if( mode != 'light') { this.lightWeights([ 0.612, 0.354, 0.707], 'base'); this.lightWeights([-0.612, 0.354, 0.707], 'base1'); this.lightWeights([ 0, -0.707, 0.707], 'base2'); } this.needsUpdate = true; } setLight(light) { if(!this.uniforms.light) throw \"Shader not initialized, wait on layer ready event for setLight.\" let x = light[0]; let y = light[1]; //map the square to the circle. let r = Math.sqrt(x*x + y*y); if(r &gt; 1) { x /= r; y /= r; } let z = Math.sqrt(Math.max(0, 1 - x*x - y*y)); light = [x, y, z]; if(this.mode == 'light') this.lightWeights(light, 'base'); this.setUniform('light', light); } setSpecularExp(value) { this.setUniform('specular_exp', value); } init(relight) { Object.assign(this, relight); if(this.colorspace == 'mycc') this.nplanes = this.yccplanes[0] + this.yccplanes[1] + this.yccplanes[2]; else this.yccplanes = [0, 0, 0]; this.planes = []; this.njpegs = 0; while(this.njpegs*3 &lt; this.nplanes) this.njpegs++; for(let i = 0; i &lt; this.njpegs; i++) this.samplers.push({ id:i, name:'plane'+i, type:'vec3' }); if(this.normals) this.samplers.push({id:this.njpegs, name:'normals', type:'vec3' }); if(this.normals) this.samplers.push({ id:this.njpegs, name:'normals', type:'vec3'}); this.material = this.materials[0]; if(this.lights) this.lights + new Float32Array(this.lights); if(this.type == \"rbf\") this.ndimensions = this.lights.length/3; if(this.type == \"bilinear\") { this.ndimensions = this.resolution*this.resolution; this.type = \"bln\"; } this.scale = this.material.scale; this.bias = this.material.bias; if(['mrgb', 'mycc'].includes(this.colorspace)) this.loadBasis(this.basis); this.uniforms = { light: { type: 'vec3', needsUpdate: true, size: 3, value: [0.0, 0.0, 1] }, specular_exp: { type: 'float', needsUpdate: false, size: 1, value: 10 }, bias: { type: 'vec3', needsUpdate: true, size: this.nplanes/3, value: this.bias }, scale: { type: 'vec3', needsUpdate: true, size: this.nplanes/3, value: this.scale }, base: { type: 'vec3', needsUpdate: true, size: this.nplanes }, base1: { type: 'vec3', needsUpdate: false, size: this.nplanes }, base2: { type: 'vec3', needsUpdate: false, size: this.nplanes } } this.lightWeights([0, 0, 1], 'base'); } lightWeights(light, basename, time) { let value; switch(this.type) { case 'ptm': value = PTM.lightWeights(light); break; case 'hsh': value = HSH.lightWeights(light); break; case 'sh' : value = SH.lightWeights(light); break; case 'rbf': value = RBF.lightWeights(light, this); break; case 'bln': value = BLN.lightWeights(light, this); break; } this.setUniform(basename, value, time); } baseLightOffset(p, l, k) { return (p*this.ndimensions + l)*3 + k; } basePixelOffset(p, x, y, k) { return (p*this.resolution*this.resolution + (x + y*this.resolution))*3 + k; } loadBasis(data) { let tmp = new Uint8Array(data); this.basis = new Float32Array(data.length); let basis = new Float32Array(tmp.length); for(let plane = 0; plane &lt; this.nplanes+1; plane++) { for(let c = 0; c &lt; this.ndimensions; c++) { for(let k = 0; k &lt; 3; k++) { let o = this.baseLightOffset(plane, c, k); if(plane == 0) this.basis[o] = tmp[o]/255; else this.basis[o] = ((tmp[o] - 127)/this.material.range[plane-1]); } } } } fragShaderSrc(gl) { let basetype = 'vec3'; //(this.colorspace == 'mrgb' || this.colorspace == 'mycc')?'vec3':'float'; let gl2 = !(gl instanceof WebGLRenderingContext); let str = `${gl2? '#version 300 es' : ''} precision highp float; precision highp int; #define np1 ${this.nplanes + 1} ${gl2? 'in' : 'varying'} vec2 v_texcoord; ${gl2? 'out' : ''} vec4 color; const mat3 T = mat3(8.1650e-01, 4.7140e-01, 4.7140e-01, -8.1650e-01, 4.7140e-01, 4.7140e-01, -1.6222e-08, -9.4281e-01, 4.7140e-01); uniform vec3 light; uniform float specular_exp; uniform vec3 bias[np1]; uniform vec3 scale[np1]; uniform ${basetype} base[np1]; uniform ${basetype} base1[np1]; uniform ${basetype} base2[np1]; `; for(let n = 0; n &lt; this.njpegs; n++) str += ` uniform sampler2D plane${n}; `; if(this.normals) str += ` uniform sampler2D normals; `; if(this.colorspace == 'mycc') str += ` const int ny0 = ${this.yccplanes[0]}; const int ny1 = ${this.yccplanes[1]}; ` switch(this.colorspace) { case 'rgb': str += RGB.render(this.njpegs, gl2); break; case 'mrgb': str += MRGB.render(this.njpegs, gl2); break; case 'mycc': str += MYCC.render(this.njpegs, this.yccplanes[0], gl2); break; } str += ` void main(void) { `; if(this.mode == 'light') { str += ` color = render(base); `; } else { if(this.normals) str += ` vec3 normal = (texture${gl2?'':'2D'}(normals, v_texcoord).zyx *2.0) - 1.0; normal.z = sqrt(1.0 - normal.x*normal.x - normal.y*normal.y); `; else str += ` vec3 normal; normal.x = dot(render(base ).xyz, vec3(1)); normal.y = dot(render(base1).xyz, vec3(1)); normal.z = dot(render(base2).xyz, vec3(1)); normal = normalize(T * normal); `; switch(this.mode) { case 'normals': str += ` normal = (normal + 1.0)/2.0; color = vec4(0.0, normal.xy, 1); `; break; case 'diffuse': str += ` color = vec4(vec3(dot(light, normal)), 1); `; break; case 'specular': default: str += ` float s = pow(dot(light, normal), specular_exp); //color = vec4(render(base).xyz*s, 1.0); color = vec4(s, s, s, 1.0); `; break; } } str += ` ${gl2?'':'gl_FragColor = color;'} }`; return str; } } class RGB { static render(njpegs, gl2) { let str = ` vec4 render(vec3 base[np1]) { vec4 rgb = vec4(0, 0, 0, 1);`; for(let j = 0; j &lt; njpegs; j++) { str += ` { vec4 c = texture${gl2?'':'2D'}(plane${j}, v_texcoord); rgb.x += base[${j}].x*(c.x - bias[${j}].x)*scale[${j}].x; rgb.y += base[${j}].y*(c.y - bias[${j}].y)*scale[${j}].y; rgb.z += base[${j}].z*(c.z - bias[${j}].z)*scale[${j}].z; } `; } str += ` return rgb; } `; return str; } } class MRGB { static render(njpegs, gl2) { let str = ` vec4 render(vec3 base[np1]) { vec3 rgb = base[0]; vec4 c; vec3 r; `; for(let j = 0; j &lt; njpegs; j++) { str += ` c = texture${gl2?'':'2D'}(plane${j}, v_texcoord); r = (c.xyz - bias[${j}])* scale[${j}]; rgb += base[${j}*3+1]*r.x; rgb += base[${j}*3+2]*r.y; rgb += base[${j}*3+3]*r.z; `; } str += ` return vec4(rgb, 1); } `; return str; } } class MYCC { static render(njpegs, ny1, gl2) { let str = ` vec3 toRgb(vec3 ycc) { vec3 rgb; rgb.g = ycc.r + ycc.b/2.0; rgb.b = ycc.r - ycc.b/2.0 - ycc.g/2.0; rgb.r = rgb.b + ycc.g; return rgb; } vec4 render(vec3 base[np1]) { vec3 rgb = base[0]; vec4 c; vec3 r; `; for(let j = 0; j &lt; njpegs; j++) { str += ` c = texture${gl2?'':'2D'}(plane${j}, v_texcoord); r = (c.xyz - bias[${j}])* scale[${j}]; `; if(j &lt; ny1) { str += ` rgb.x += base[${j}*3+1].x*r.x; rgb.y += base[${j}*3+2].y*r.y; rgb.z += base[${j}*3+3].z*r.z; `; } else { str += ` rgb.x += base[${j}*3+1].x*r.x; rgb.x += base[${j}*3+2].x*r.y; rgb.x += base[${j}*3+3].x*r.z; `; } } str += ` return vec4(toRgb(rgb), 1); } `; return str; } } /* PTM utility functions */ class PTM { /* @param {Array} v expects light direction as [x, y, z] */ static lightWeights(v) { let b = [1.0, v[0], v[1], v[0]*v[0], v[0]*v[1], v[1]*v[1]]; let base = new Float32Array(18); for(let i = 0; i &lt; 18; i++) base[3*i] = base[3*i+1] = base[3*i+2] = b[i]; return base; } } /* HSH utility functions */ class HSH { /* @param {Array} v expects light direction as [x, y, z] */ static lightWeights(v) { let PI = 3.1415; let phi = Math.atan2(v[1], v[0]); if (phi &lt; 0) phi = 2 * PI + phi; let theta = Math.min(Math.acos(v[2]), PI / 2 - 0.1); let cosP = Math.cos(phi); let cosT = Math.cos(theta); let cosT2 = cosT * cosT; let b = [ 1.0 / Math.sqrt(2 * PI), Math.sqrt(6 / PI) * (cosP * Math.sqrt(cosT-cosT2)), Math.sqrt(3 / (2 * PI)) * (-1 + 2*cosT), Math.sqrt(6 / PI) * (Math.sqrt(cosT - cosT2) * Math.sin(phi)), Math.sqrt(30 / PI) * (Math.cos(2 * phi) * (-cosT + cosT2)), Math.sqrt(30 / PI) * (cosP*(-1 + 2 * cosT) * Math.sqrt(cosT - cosT2)), Math.sqrt(5 / (2 * PI)) * (1 - 6 * cosT + 6 * cosT2), Math.sqrt(30 / PI) * ((-1 + 2 * cosT) * Math.sqrt(cosT - cosT2) * Math.sin(phi)), Math.sqrt(30 / PI) * ((-cosT + cosT2) * Math.sin(2*phi)) ]; let base = new Float32Array(27); for(let i = 0; i &lt; 27; i++) base[3*i] = base[3*i+1] = base[3*i+2] = b[i]; return base; } } class SH { /* @param {Array} v expects light direction as [x, y, z] */ static lightWeights(v) { let PI = 3.1415; let A = 0.5*Math.sqrt(3.0/PI); let B = 0.5*Math.sqrt(15/PI); let b = [ 0.5/Math.sqrt(PI), A*v[0], A*v[2], A*v[1], B*v[0]*v[1], B*v[0]*v[2], 0.5*Math.sqrt(5/PI)*(3*v[2]*v[2] - 1), B*v[1]*v[2], 0.5*B*(v[1]*v[1] - v[0]*v[0]) ]; let base = new Float32Array(27); for(let i = 0; i &lt; 27; i++) base[3*i] = base[3*i+1] = base[3*i+2] = b[i]; return base; } } class RBF { /* @param {Array} v expects light direction as [x, y, z] */ static lightWeights(lpos, shader) { let weights = RBF.rbf(lpos, shader); let np = shader.nplanes; let lweights = new Float32Array((np + 1) * 3); for(let p = 0; p &lt; np+1; p++) { for(let k = 0; k &lt; 3; k++) { for(let l = 0; l &lt; weights.length; l++) { let o = shader.baseLightOffset(p, weights[l][0], k); lweights[3*p + k] += weights[l][1]*shader.basis[o]; } } } return lweights; } static rbf(lpos, shader) { let radius = 1/(shader.sigma*shader.sigma); let weights = new Array(shader.ndimensions); //compute rbf weights let totw = 0.0; for(let i = 0; i &lt; weights.length; i++) { let dx = shader.lights[i*3+0] - lpos[0]; let dy = shader.lights[i*3+1] - lpos[1]; let dz = shader.lights[i*3+2] - lpos[2]; let d2 = dx*dx + dy*dy + dz*dz; let w = Math.exp(-radius * d2); weights[i] = [i, w]; totw += w; } for(let i = 0; i &lt; weights.length; i++) weights[i][1] /= totw; //pick only most significant and renormalize let count = 0; totw = 0.0; for(let i = 0; i &lt; weights.length; i++) { if(weights[i][1] &gt; 0.001) { weights[count++] = weights[i]; totw += weights[i][1]; } } weights = weights.slice(0, count); for(let i = 0; i &lt; weights.length; i++) weights[i][1] /= totw; return weights; } } class BLN { static lightWeights(lpos, shader) { let np = shader.nplanes; let s = Math.abs(lpos[0]) + Math.abs(lpos[1]) + Math.abs(lpos[2]); //rotate 45 deg. let x = (lpos[0] + lpos[1])/s; let y = (lpos[1] - lpos[0])/s; x = (x + 1.0)/2.0; y = (y + 1.0)/2.0; x = x*(shader.resolution - 1.0); y = y*(shader.resolution - 1.0); let sx = Math.min(shader.resolution-2, Math.max(0, Math.floor(x))); let sy = Math.min(shader.resolution-2, Math.max(0, Math.floor(y))); let dx = x - sx; let dy = y - sy; //bilinear interpolation coefficients. let s00 = (1 - dx)*(1 - dy); let s10 = dx *(1 - dy); let s01 = (1 - dx)* dy; let s11 = dx * dy; let lweights = new Float32Array((np + 1) * 3); //TODO optimize away basePixel for(let p = 0; p &lt; np+1; p++) { for(let k = 0; k &lt; 3; k++) { let o00 = shader.basePixelOffset(p, sx, sy, k); let o10 = shader.basePixelOffset(p, sx+1, sy, k); let o01 = shader.basePixelOffset(p, sx, sy+1, k); let o11 = shader.basePixelOffset(p, sx+1, sy+1, k); lweights[3*p + k] = s00*shader.basis[o00] + s10*shader.basis[o10] + s01*shader.basis[o01] + s11*shader.basis[o11]; } } return lweights; } } export { ShaderRTI } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Transform.js.html":{"id":"Transform.js.html","title":"Source: Transform.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Transform.js /** * * @param {number} x position * @param {number} y position * @param {number} z scale * @param {number} a rotation in degrees * @param {number} t time * */ import { BoundingBox } from \"./BoundingBox\"; class Transform { constructor(options) { Object.assign(this, { x:0, y:0, z:1, a:0, t:0 }); if(!this.t) this.t = performance.now(); if(typeof(options) == 'object') Object.assign(this, options); } copy() { let transform = new Transform(); Object.assign(transform, this); return transform; } apply(x, y) { //TODO! ROTATE let r = Transform.rotate(x, y, this.a); return { x: r.x*this.z + this.x, y: r.y*this.z + this.y } } inverse() { let r = Transform.rotate(this.x/this.z, this.y/this.z, -this.a); return new Transform({x:-r.x, y:-r.y, z:1/this.z, a:-this.a, t:this.t}); } static normalizeAngle(a) { while(a &gt; 360) a -= 360; while(a &lt; 0) a += 360; return a; } static rotate(x, y, angle) { angle = Math.PI*(angle/180); let ex = Math.cos(angle)*x + Math.sin(angle)*y; let ey = -Math.sin(angle)*x + Math.cos(angle)*y; return {x:ex, y:ey}; } // first get applied this (a) then transform (b). compose(transform) { let a = this.copy(); let b = transform; a.z *= b.z; a.a += b.a; var r = Transform.rotate(a.x, a.y, b.a); a.x = r.x*b.z + b.x; a.y = r.y*b.z + b.y; return a; } /* transform the box (for example -w/2, -h/2 , w/2, h/2 in scene coords) */ transformBox(lbox) { let box = new BoundingBox(); for(let i = 0; i &lt; 4; i++) { let c = lbox.corner(i); let p = this.apply(c[0], c[1]); box.mergePoint(p); } return box; } /* get the bounding box (in image coordinate sppace) of the vieport. the viewport has y -&gt; pointing up the image and screen transform has y pointing down. hence the inversion. */ getInverseBox(viewport) { let inverse = this.inverse(); let corners = [ {x:viewport.x, y:viewport.y}, {x:viewport.x + viewport.dx, y:viewport.y}, {x:viewport.x, y:viewport.y + viewport.dy}, {x:viewport.x + viewport.dx, y:viewport.y + viewport.dy} ]; let box = new BoundingBox(); for(let corner of corners) { let p = inverse.apply(corner.x -viewport.w/2, -corner.y + viewport.h/2); box.mergePoint(p); } return box; } interpolate(source, target, time, easing) { let t = (target.t - source.t); this.t = time; if(time &lt; source.t) return Object.assign(this, source); if(time &gt; target.t || t &lt; 0.0001) return Object.assign(this, target); let tt = (time - source.t)/t; switch(easing) { case 'ease-out': tt = 1 - Math.pow(1 - tt, 2); break; case 'ease-in-out': tt = tt &lt; 0.5 ? 2*tt*tt : 1 - Math.pow(-2 * tt + 2, 2) / 2; break; } let st = 1 -tt; for(let i of ['x', 'y', 'z', 'a']) this[i] = (st*source[i] + tt*target[i]); } /** * Combines the transform with the viewport to the viewport with the transform * @param {Object} transform a {@link Transform} class. */ projectionMatrix(viewport) { let z = this.z; // In coords with 0 in lower left corner map x0 to -1, and x0+v.w to 1 // In coords with 0 at screen center and x0 at 0, map -v.w/2 -&gt; -1, v.w/2 -&gt; 1 // With x0 != 0: x0 -&gt; x0-v.w/2 -&gt; -1, and x0+dx -&gt; x0+v.dx-v.w/2 -&gt; 1 // Where dx is viewport width, while w is window width //0, 0 &lt;-&gt; viewport.x + viewport.dx/2 (if x, y = let zx = 2/viewport.dx; let zy = 2/viewport.dy; let dx = zx * this.x + (2/viewport.dx)*(viewport.w/2-viewport.x)-1; let dy = -zy * this.y + (2/viewport.dy)*(viewport.h/2-viewport.y)-1; let a = Math.PI *this.a/180; let matrix = [ Math.cos(a)*zx*z, Math.sin(a)*zy*z, 0, 0, -Math.sin(a)*zx*z, Math.cos(a)*zy*z, 0, 0, 0, 0, 1, 0, dx, dy, 0, 1]; return matrix; } /** * TODO (if needed) */ toMatrix() { let z = this.z; return [ z, 0, 0, 0, 0, z, 0, 0, 0, 0, 1, 0, z*x, z*y, 0, 1, ]; } /** * Transform p from scene (0 at image center) to [0,wh] * @param {*} viewport viewport(x,y,dx,dy,w,h) * @param {*} p point in scene: 0,0 at image center */ sceneToViewportCoords(viewport, p) { return [p[0] * this.z + this.x - viewport.x + viewport.w/2, p[1] * this.z - this.y + viewport.y + viewport.h/2 ]; } /** * Transform p from [0,wh] to scene (0 at image center) * * @param {*} viewport viewport(x,y,dx,dy,w,h) * @param {*} p point in range [0..w-1,0..h-1] */ viewportToSceneCoords(viewport, p) { return [(p[0] + viewport.x - viewport.w/2 - this.x) / this.z, (p[1] - viewport.y - viewport.h/2 + this.y) / this.z]; } } function matrixMul(a, b) { let r = new Array(16); for (let i = 0; i &lt; 4; i++) { for (let j = 0; j &lt; 4; j++) { r[j + i*4] = 0; for (let k = 0; k &lt; N; k++) { r[j + i*4] += a[k + i*4]*b[k + j*4] } } } return r; } function matMul(a, b) { let r = new Array(16); r[ 0] = a[0]*b[0] + a[4]*b[1] + a[8]*b[2] + a[12]*b[3]; r[ 1] = a[1]*b[0] + a[5]*b[1] + a[9]*b[2] + a[13]*b[3]; r[ 2] = a[2]*b[0] + a[6]*b[1] + a[10]*b[2] + a[14]*b[3]; r[ 3] = a[3]*b[0] + a[7]*b[1] + a[11]*b[2] + a[15]*b[3]; r[ 4] = a[0]*b[4] + a[4]*b[5] + a[8]*b[6] + a[12]*b[7]; r[ 5] = a[1]*b[4] + a[5]*b[5] + a[9]*b[6] + a[13]*b[7]; r[ 6] = a[2]*b[4] + a[6]*b[5] + a[10]*b[6] + a[14]*b[7]; r[ 7] = a[3]*b[4] + a[7]*b[5] + a[11]*b[6] + a[15]*b[7]; r[ 8] = a[0]*b[8] + a[4]*b[9] + a[8]*b[10] + a[12]*b[11]; r[ 9] = a[1]*b[8] + a[5]*b[9] + a[9]*b[10] + a[13]*b[11]; r[10] = a[2]*b[8] + a[6]*b[9] + a[10]*b[10] + a[14]*b[11]; r[11] = a[3]*b[8] + a[7]*b[9] + a[11]*b[10] + a[15]*b[11]; r[12] = a[0]*b[12] + a[4]*b[13] + a[8]*b[14] + a[12]*b[15]; r[13] = a[1]*b[12] + a[5]*b[13] + a[9]*b[14] + a[13]*b[15]; r[14] = a[2]*b[12] + a[6]*b[13] + a[10]*b[14] + a[14]*b[15]; r[15] = a[3]*b[12] + a[7]*b[13] + a[11]*b[14] + a[15]*b[15]; return r; } export { Transform, matMul } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Viewer.js.html":{"id":"Viewer.js.html","title":"Source: Viewer.js","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Source: Viewer.js import { Canvas } from './Canvas.js' import { Camera } from './Camera.js' import { PointerManager } from './PointerManager.js' /** * Manages an OpenLIME viewer functionality on a canvas * how do I write more substantial documentation. * * @param {div} div of the DOM or selector (es. '#canvasid'), or a canvas. * @param {string} options is a url to a JSON describing the viewer content * @param {object} options is a JSON describing the viewer content * * **animate**: default *true*, calls requestAnimation() and manages refresh. * * **background**: css style for background (overwrites css if present) * * @example * const lime = new OpenLIME.OpenLIME('.openlime'); * // .openlime is the class of a DIV element in the DOM. */ class Viewer { constructor(div, options) { Object.assign(this, { background: null, canvas: {}, controllers: [], camera: new Camera() }); if (typeof (div) == 'string') div = document.querySelector(div); if (!div) throw \"Missing element parameter\"; Object.assign(this, options); if (this.background) div.style.background = this.background; this.containerElement = div; this.canvasElement = div.querySelector('canvas'); if (!this.canvasElement) { this.canvasElement = document.createElement('canvas'); div.prepend(this.canvasElement); } this.overlayElement = document.createElement('div'); this.overlayElement.classList.add('openlime-overlay'); this.containerElement.appendChild(this.overlayElement); this.canvas = new Canvas(this.canvasElement, this.overlayElement, this.camera, this.canvas); this.canvas.addEvent('update', () =&gt; { this.redraw(); }); this.pointerManager = new PointerManager(this.overlayElement); this.canvasElement.addEventListener('contextmenu', (e) =&gt; { e.preventDefault(); return false; }); var resizeobserver = new ResizeObserver(entries =&gt; { for (let entry of entries) { this.resize(entry.contentRect.width, entry.contentRect.height); } }); resizeobserver.observe(this.canvasElement); this.resize(this.canvasElement.clientWidth, this.canvasElement.clientHeight); } /* Convenience function, it actually passes to Canvas */ addLayer(id, layer) { canvas.addLayer(id, layer); } /** * Resize the canvas (and the overlay) and triggers a redraw. */ resize(width, height) { // Test with retina display! this.canvasElement.width = width * window.devicePixelRatio; this.canvasElement.height = height * window.devicePixelRatio; this.camera.setViewport({ x: 0, y: 0, dx: width, dy: height, w: width, h: height }); this.canvas.prefetch(); this.redraw(); } /** * * Schedule a drawing. */ redraw() { if (this.animaterequest) return; this.animaterequest = requestAnimationFrame((time) =&gt; { this.draw(time); }); } /** * Do not call this if OpenLIME is animating, use redraw() * @param {time} time as in performance.now() */ draw(time) { if (!time) time = performance.now(); this.animaterequest = null; let viewport = this.camera.viewport; let transform = this.camera.getCurrentTransform(time); let done = this.canvas.draw(time); if (!done) this.redraw(); } } export { Viewer }; Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"modules.list.html":{"id":"modules.list.html","title":"Modules","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Modules Classes Annotation Camera Canvas Controller Layer LayerAnnotation LayerBRDF LayerCombiner LayerImage LayerLens LayerRTI LayerSvgAnnotation Layout OpenLIME PointerManager Raster Shader ShaderBRDF ShaderCombiner ShaderRTI Viewer Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"classes.list.html":{"id":"classes.list.html","title":"Classes","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Classes Classes Annotation Camera Canvas Controller Layer LayerAnnotation LayerBRDF LayerCombiner LayerImage LayerLens LayerRTI LayerSvgAnnotation Layout OpenLIME PointerManager Raster Shader ShaderBRDF ShaderCombiner ShaderRTI Viewer Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"tutorials.list.html":{"id":"tutorials.list.html","title":"Howto","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Howto Classes Annotation Camera Canvas Controller Layer LayerAnnotation LayerBRDF LayerCombiner LayerImage LayerLens LayerRTI LayerSvgAnnotation Layout OpenLIME PointerManager Raster Shader ShaderBRDF ShaderCombiner ShaderRTI Viewer Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"index.html":{"id":"index.html","title":"Index","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME OpenLIME (Open Layered IMage Explorer) Web-based, advanced images viewer (RTI, multispectral, BRDF, etc. ) Installing npm Ubuntu sudo apt install npm Ubuntu 18.04 You might have some problem using the old npm version shipped with Ubuntu18.04, and even upgrading it. This worked for me: sudo npm install -g npm@latest-6 Windows To obtain npm for Windows, you need to download the Windows version of node.js from https://nodejs.org/en/download/ . You can download either the Windows Installer (.msi) or the Windows Binary (.zip). If you download and expand the Windows Binary zip file, you will afterwards need to set your PATH variable to include the directory that contains the npm executable (this directory is the subdirectory node_modules\\npm\\bin). Setting up npm (all platforms) The following step should be performed in the openlime directory that was cloned from this repository. Before using npm, you need to install the required packages locally. This only needs to be done once. The following command tells npm to download all the webpack packages (and their dependencies) listed in the package.json file. These will be put in the ./node_modules directory. npm install The downloaded packages include rollup, documentation, and nodemon, which will be used below. Using npm (all platforms) These steps should be performed in the openlime directory that was cloned from this repository. Build the code The following command reads the javascript code in ./src, and puts the transpiled webpack code in ./dist/main.js. npm run build The webpack code is used, for example, by the ./dist/index.html web page. Run the node.js server If you wish, you can run the node.js development server to serve your web pages. This server will use ./dist as the home directory. The server is run in \"hot\" mode, which means that whenever you change a file in the ./src directory, the webpack code will automatically be rebuilt, and your web browser will automatically refresh, to reflect your latest changes. npm run start Then access the demo app at http://localhost:8080 (which by default is ./dist/index.html). If you prefer to serve from a different port, say 8088, you can call npm run start -- --port 8088 Create a rollup file to use with other servers You do not need to use node.js as the server. Instead, you can use the &lt;script&gt; approach, embedding a rollup file, either ./build/openlime.min.js or ./build/openlime.js, in your web page. The files ./dist/ui_custom.html and ./dist/ui_svg.html are examples of this approach. Such files will display correctly when served from any web server. To create the rollup files, call rollup: npm run rollup Keep the rollup files up to date If you keep a nodemon (node monitor) script running, it will automatically update the rollup files ./build/openlime.min.js and ./build/openlime.js whenever anything changes in the ./src directory. Note that, unlike with the node.js server, the browser will not refresh automatically; you will have to do that yourself once the rollup files have been updated. npm run nodemon Create documentation The documentation is created from structured comments in the source code (in ./src). Once created, it is accessible from ./docs/index.html npm run documentation Customization skin.css skin.svg Run svgo -p 1 skin.svg -o skin.min.svg to minimize svg. Documentation.js supports markdown syntax and JSDoc syntax. JSON example of the configuration: { camera: { }, canvas: { rasters: [ { id: name: width: //optional height: //optional url: layout: &lt;image|google|deepzoom|zoomify|iip|iiif&gt; //optional if can be determined from the url. } ] }, overlay: { } } Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Annotation.html":{"id":"Annotation.html","title":"Class: Annotation","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Annotation Annotation coordinates for annotations are relative to the top left corner!!!! new Annotation() Source: Annotation.js, line 4 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Camera.html":{"id":"Camera.html","title":"Class: Camera","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Camera Camera NOTICE TODO: the camera has the transform relative to the whole canvas NOT the viewport. new Camera(options) Parameters: Name Type Description options object bounded: limit translation of the camera to the boundary of the scene. maxZoom: maximum zoom, 1:maxZoom is screen pixel to image pixel ratio. minZoom: minimum zoom, *minScreenFraction: the minimum portion of the screen to zoom in *maxFixedZoom: maximum pixel size Signals: Emits 'update' event when target is changed. Source: Camera.js, line 16 Methods fit(box, dt, size) Parameters: Name Type Description box Array fit the specified rectangle [minx, miny, maxx, maxy] in the canvas. dt number animation duration in millisecond size string how to fit the image: &lt;contain | cover&gt; default is contain (and cover is not implemented Source: Camera.js, line 232 mapToScene() Map coordinate relative to the canvas into scene coords. using the specified transform. Source: Camera.js, line 76 Returns: [X, Y] in scene coordinates. setViewport() Set the viewport and updates the camera for an as close as possible. Source: Camera.js, line 54 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Canvas.html":{"id":"Canvas.html","title":"Class: Canvas","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Canvas Canvas new Canvas(canvas, overlay, camera, options) Parameters: Name Type Description canvas Element | String dom element or query selector for a element. overlay Element DIV containing annotations, TODO: at the moment it is just passed to the layers (might need refactoring) camera Camera (see Camera) options Object layers: Object specifies layers (see. Layer) preserveDrawingBuffer needed for screenshots (otherwise is just a performance penalty) Signals: Emits \"update\" event when a layer updates or is added or removed. Source: Canvas.js, line 18 Methods prefetch(transform) This function have each layer to check which tiles are needed and schedule them for download. Parameters: Name Type Description transform object is the camera position (layer will combine with local transform). Source: Canvas.js, line 177 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Controller.html":{"id":"Controller.html","title":"Class: Controller","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Controller Controller Virtual nase class for controllers: classes that handle mouse and touch events and links to pan, zoom, etc. Callbacks supporte are: panStart(event) calling event.preventDefault() will capture the panning gestire panMove(event) panEnd(event) pinchStart(event) calling event.preventDefault() will capture the pinch gestire pinchMove(event) pinchEnd(event) wheelDelta(event) singleTap(event) wheelDelta(event) doubleTap(event) resize(event) In general event.preventDefault() will capture the event and wont be propagated to other controllers. new Controller(options) Parameters: Name Type Description options options panDelay inertia of the movement in ms for panning movements (default 100) zoomDelay a zoom event is smoothed over this delay in ms (default 200) priority higher priority controllers are invoked in advance. Source: Controller.js, line 25 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Layer.html":{"id":"Layer.html","title":"Class: Layer","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Layer Layer new Layer(id, options) Parameters: Name Type Description id string unique id for layer. options object label: transform: relative coordinate transformation from layer to canvas visible: where to render or not zindex: stack ordering of the layer higher on top opacity: from 0.0 to 1.0 (0.0 is fully transparent) rasters: rasters used for rendering. controls: shader parameters that can be modified (eg. light direction) shader: shader used for rendering layout: one of image, deepzoom, google, iiif, or zoomify mipmapBias: default 0.4, when to switch between different levels of the mipmap, 0 means switch as early as the tile would be enlarged on the screen, while 1.0 means switch when 1 pixel in tile is &gt;= 2 pixels on screen prefetchBorder: border tiles prefetch (default 1) maxRequest: max number of simultaneous requests (should be GLOBAL not per layer!) default 4 Source: Layer.js, line 24 Methods draw() render the Source: Layer.js, line 291 prefetch({object, is) Parameters: Name Type Description {object transform is the canvas coordinate transformation is viewport the viewport for the rendering, note: for lens might be different! Where we change it? here layer should know! Source: Layer.js, line 472 setupTiles() If layout is ready and shader is assigned, creates or update tiles to keep track of what is missing. Source: Layer.js, line 408 setVisible(visible) Parameters: Name Type Description visible bool Source: Layer.js, line 159 setZindex(zindex) Parameters: Name Type Description zindex int Source: Layer.js, line 168 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerAnnotation.html":{"id":"LayerAnnotation.html","title":"Class: LayerAnnotation","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: LayerAnnotation LayerAnnotation SVG or OpenGL polygons/lines/points annotation layer new LayerAnnotation(options) Parameters: Name Type Description options object svgURL: url for the svg containing the annotations svgXML: svg string containing the annotatiosn geometry: TODO: should contain the areas/lines/points for OpenGL rendering style: css style for the annotation elements (shadow dom allows css to apply only to this layer) annotations: collection of annotations info: each annotations is id: { label, svg (optional), data (custom data) (TODO) Source: LayerAnnotation.js, line 15 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerBRDF.html":{"id":"LayerBRDF.html","title":"Class: LayerBRDF","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: LayerBRDF LayerBRDF Extends Layer. new LayerBRDF(options) Parameters: Name Type Description options options Same as Layer, but channels(ks,kd,normals,gloss) are required. Source: LayerBRDF.js, line 10 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerCombiner.html":{"id":"LayerCombiner.html","title":"Class: LayerCombiner","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: LayerCombiner LayerCombiner Combines other layers (using a framebuffer) using a shader. Lens is an example. Extends Layer. new LayerCombiner(options) Parameters: Name Type Description options options Same as Layer, but url and layout are required. Source: LayerCombiner.js, line 8 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerImage.html":{"id":"LayerImage.html","title":"Class: LayerImage","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: LayerImage LayerImage Display a simple image. Extends Layer. new LayerImage(options) Parameters: Name Type Description options options Same as Layer, but url and layout are required. Source: LayerImage.js, line 10 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerLens.html":{"id":"LayerLens.html","title":"Class: LayerLens","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: LayerLens LayerLens options must contain one layer and lens = {x:, y:, r:, border: } new LayerLens() Source: LayerLens.js, line 8 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerRTI.html":{"id":"LayerRTI.html","title":"Class: LayerRTI","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: LayerRTI LayerRTI Extends Layer. new LayerRTI(options) Parameters: Name Type Description options options Same as Layer, but url and layout are required. url: points to a relight format .json plane: url for the first coefficient (plane_0), needed for IIIF and IIP (without /info.json) Source: LayerRTI.js, line 13 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"LayerSvgAnnotation.html":{"id":"LayerSvgAnnotation.html","title":"Class: LayerSvgAnnotation","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: LayerSvgAnnotation LayerSvgAnnotation SVG or OpenGL polygons/lines/points annotation layer new LayerSvgAnnotation(options) Parameters: Name Type Description options object svgURL: url for the svg containing the annotations svgXML: svg string containing the annotatiosn style: css style for the annotation elements (shadow dom allows css to apply only to this layer) Source: LayerSvgAnnotation.js, line 14 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Layout.html":{"id":"Layout.html","title":"Class: Layout","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Layout Layout new Layout(url, type) Parameters: Name Type Description url string | Object URL of the image or the tiled config file, type string select one among: &lt;image, google, deepzoom, zoomify, iip, iiif&gt; Source: Layout.js, line 7 Methods index() Each tile is assigned an unique number. Source: Layout.js, line 79 &lt;async&gt; initDeepzoom() Expects the url to point to .dzi config file Source: Layout.js, line 272 &lt;async&gt; initGoogle() url points to the folder (without /) width and height must be defined Source: Layout.js, line 246 &lt;async&gt; initZoomify() Expects the url to point to ImageProperties.xml file. Source: Layout.js, line 356 neededBox(viewport, border) Given a viewport and a transform computes the tiles needed for each level. Parameters: Name Type Description viewport array array with left, bottom, width, height border border is radius (in tiles units) of prefetch Source: Layout.js, line 196 Returns: with level: the optimal level in the pyramid, pyramid: array of bounding boxes in tile units. Type object tileCoords() Return the coordinates of the tile (in [0, 0, w h] image coordinate system) and the texture coords associated. Source: Layout.js, line 130 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"module-OpenLIME.html":{"id":"module-OpenLIME.html","title":"Module: OpenLIME","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Module: OpenLIME Source: OpenLIME.js, line 18 Classes OpenLIME Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"module-OpenLIME-OpenLIME.html":{"id":"module-OpenLIME-OpenLIME.html","title":"Class: OpenLIME","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: OpenLIME OpenLIME~ OpenLIME Manages an OpenLIME viewer functionality on a canvas how do I write more substantial documentation. new OpenLIME(div, options, options) Parameters: Name Type Description div div of the DOM or selector (es. '#canvasid'), or a canvas. options string is a url to a JSON describing the viewer content options object is a JSON describing the viewer content animate: default true, calls requestAnimation() and manages refresh. background: css style for background (overwrites css if present) Source: OpenLIME.js, line 35 Example const lime = new OpenLIME.OpenLIME('.openlime'); // .openlime is the class of a DIV element in the DOM. Methods draw(time) Do not call this if OpenLIME is animating, use redraw() Parameters: Name Type Description time time as in performance.now() Source: OpenLIME.js, line 125 redraw() Schedule a drawing. Source: OpenLIME.js, line 116 resize() Resize the canvas (and the overlay) and triggers a redraw. Source: OpenLIME.js, line 100 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"PointerManager.html":{"id":"PointerManager.html","title":"Class: PointerManager","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: PointerManager PointerManager Manages handles simultaneous events from a target. how do I write more substantial documentation. new PointerManager(target, options) Parameters: Name Type Description target div is the DOM element from which the events are generated options object is a JSON describing the options diagonal: default 27, the screen diagonal in inch Source: PointerManager.js, line 9 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Raster.html":{"id":"Raster.html","title":"Class: Raster","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Raster Raster Raster is a providers of images and planes of coefficies. It support all files format supported by browser and a set of tiled formats. Layout can be: image: a single image (.jpg, .png etc.) google: there is no config file, so layout, suffix is mandatory if not .jpg, and url is the base folder of the tiles. deepzoom: requires only url, can be autodetected from the extension (.dzi) zoomify: requires url, can be autodetected, from the ImageProperties.xml, suffix is required if not .jpg iip: requires url, can be autodetected from the url iiif: layout is mandatory, url should point to base url {scheme}://{server}{/prefix}/{identifier} new Raster(id, url, options) Parameters: Name Type Description id string an unique id for each raster url url of the content options object type: vec3 (default value) for standard images, vec4 when including alpha, vec2, float other purpouses. attribute: &lt;coeff|kd|ks|gloss|normals|dem&gt; meaning of the image. colorSpace: &lt;linear|srgb&gt; colorspace used for rendering. Source: Raster.js, line 21 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Shader.html":{"id":"Shader.html","title":"Class: Shader","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Shader Shader new Shader(options) Parameters: Name Type Description options object label: used for menu samplers: array of rasters {id:, type: } color, normals, etc. uniforms: type = &lt;vec4|vec3|vec2|float|int&gt;, needsUpdate controls when updated in gl, size is unused, value is and array or a float, we also want to support interpolation: source (value is the target), start, end are the timing (same as camera interpolation) body: code actually performing the rendering, needs to return a vec4 name: name of the body function Source: Shader.js, line 12 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"ShaderBRDF.html":{"id":"ShaderBRDF.html","title":"Class: ShaderBRDF","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: ShaderBRDF ShaderBRDF new ShaderBRDF(options) Parameters: Name Type Description options object mode: default is ward, can be [ward, diffuse, specular, normals] Source: ShaderBRDF.js, line 8 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"ShaderCombiner.html":{"id":"ShaderCombiner.html","title":"Class: ShaderCombiner","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: ShaderCombiner ShaderCombiner new ShaderCombiner(options) Parameters: Name Type Description options object compose: compose operation: add, subtract, multiply, etc. Source: ShaderCombiner.js, line 8 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"ShaderRTI.html":{"id":"ShaderRTI.html","title":"Class: ShaderRTI","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: ShaderRTI ShaderRTI new ShaderRTI(options) Parameters: Name Type Description options object compose: compose operation: add, subtract, multiply, etc. Source: ShaderRTI.js, line 8 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"Viewer.html":{"id":"Viewer.html","title":"Class: Viewer","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Class: Viewer Viewer Manages an OpenLIME viewer functionality on a canvas how do I write more substantial documentation. new Viewer(div, options, options) Parameters: Name Type Description div div of the DOM or selector (es. '#canvasid'), or a canvas. options string is a url to a JSON describing the viewer content options object is a JSON describing the viewer content animate: default true, calls requestAnimation() and manages refresh. background: css style for background (overwrites css if present) Source: Viewer.js, line 21 Example const lime = new OpenLIME.OpenLIME('.openlime'); // .openlime is the class of a DIV element in the DOM. Methods draw(time) Do not call this if OpenLIME is animating, use redraw() Parameters: Name Type Description time time as in performance.now() Source: Viewer.js, line 109 redraw() Schedule a drawing. Source: Viewer.js, line 100 resize() Resize the canvas (and the overlay) and triggers a redraw. Source: Viewer.js, line 86 Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "},"tutorial-getting-started.html":{"id":"tutorial-getting-started.html","title":"Tutorial: Getting started with OpenLIME","body":" OpenLIME Modules OpenLIME Classes AnnotationCameraCanvasControllerLayerLayerAnnotationLayerBRDFLayerCombinerLayerImageLayerLensLayerRTILayerSvgAnnotationLayoutOpenLIME~OpenLIMEPointerManagerRasterShaderShaderBRDFShaderCombinerShaderRTIViewer Howto Getting started with OpenLIME Getting started with OpenLIME The OpenLIME framework is designed to make image viewers easy to use, even for inexperienced users. A very simple interface allows you to create visualisation tools without having to deal with the complexity of the application. Here is how to get a complete viewer in a few lines of code! const lime = new OpenLIME('#openlime', { background: 'black', canvas: { preserveDrawingBuffer: true} }); const layer0 = new Layer({layout: 'deepzoom1px', type: 'image', url: './img/duck.dzi'}); lime.canvas.addLayer('img', layer0); const ui = new UIBasic(lime); lime.draw(); Useful videos Ã— Search results Close ISTI - CNR &amp; CRS4 - ViC "}}
    </script>

    <script type="text/javascript">
        $(document).ready(function() {
            Searcher.init();
        });

        $(window).on("message", function(msg) {
            var msgData = msg.originalEvent.data;

            if (msgData.msgid != "docstrap.quicksearch.start") {
                return;
            }

            var results = Searcher.search(msgData.searchTerms);

            window.parent.postMessage({"results": results, "msgid": "docstrap.quicksearch.done"}, "*");
        });
    </script>
</body>
</html>
